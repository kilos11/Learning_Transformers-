{"metadata":{"colab":{"authorship_tag":"ABX9TyMwA9aIcYfPu6pSnuRba9Tl","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"03be34de531543cd9f476962c93fc4cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09dae082821d4ee2acbc9149f469f61f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25dcba5048b944929b22192566ed8abf","IPY_MODEL_f033fd9a698246f99784b7a3e35ff4e8","IPY_MODEL_dd3781e0b42949e3b019dbc8b5341af5"],"layout":"IPY_MODEL_7d72b1d2091a4c42925e3fe507dbf2ae"}},"0afb40a516f04a11ab3c5f8edfc1b807":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f746a4c28c4476c981c4bc49f8a088c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e23474e123b24f59ae1ad6485dcf79ff","placeholder":"​","style":"IPY_MODEL_e9b1b14c911742f1b9140f3d7523b9a0","value":"Generating test split: 100%"}},"127cca0f1da34a5989861482a9685a22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12a69edf5e0b4e64bea53d40eb8baf58":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"135e6fa6fe0641b28d86d399b9f8f577":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b41c1355dab44561b8e9a2de1604cd59","placeholder":"​","style":"IPY_MODEL_dd6ef1b72551453c8d7979a2a6888f27","value":" 6.36M/6.36M [00:00&lt;00:00, 34.4MB/s]"}},"17d16550094c4e72847fa2d1ab117cee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a43025b9f7414f1cb2b1bd4f606a51c0","placeholder":"​","style":"IPY_MODEL_929bd6560db34439a72bbd0666fbc618","value":"Downloading data: 100%"}},"18aaf874cf174b1eba37023893d6dc41":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19d90a1047924bdc95a0d5bbb9bfe333":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1adf760cc9a84c188658e6131e078f61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2df00fe657594027aa8c28dc0c6f6074","placeholder":"​","style":"IPY_MODEL_babfaefefa9b44578094110addfa4459","value":" 733k/733k [00:00&lt;00:00, 2.63MB/s]"}},"22f1f54e147d4d6dadd5f12384c4be4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23e0c67c15e24ea195ea0bec1507e610":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25dcba5048b944929b22192566ed8abf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_420a9a30bbd34e50ade142fb0c0e91c7","placeholder":"​","style":"IPY_MODEL_53b2bd4d12b64de990b7c15c0b9923e8","value":"Generating validation split: 100%"}},"2746865f9403452baa6014d61074ed07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2955ac568e674a35b53f13b78e3d95ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b8bff7537524732982f751a46010a89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd41194ecb5f4d5fa2b9975ba5035d69","placeholder":"​","style":"IPY_MODEL_2746865f9403452baa6014d61074ed07","value":" 4358/4358 [00:00&lt;00:00, 73190.93 examples/s]"}},"2df00fe657594027aa8c28dc0c6f6074":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3533db5415c84aadb2dc7c6b544741fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a527ff8d21048199a8ebe2311581304":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4800f3c23be48e68b02881923a23dab","max":732610,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4248eaf6f914682a22c1703d75a7383","value":732610}},"3e715ad1d15548de92dcd0ed42f1b625":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"420a9a30bbd34e50ade142fb0c0e91c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4360bfc15e484e01a533ac83a13ec8e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45a4a1114106462e845445c47feef65e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1528cca78704db8adb5a59813531f9c","max":6357543,"min":0,"orientation":"horizontal","style":"IPY_MODEL_973b76e1223d409c90b6771a2eafdefc","value":6357543}},"45a512eacc4d424c86c64da04bb7be61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e5ba0fbb2274a26b4047ccebf88ef02":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50604647008f4b9bb3456d6abb93a342":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53b2bd4d12b64de990b7c15c0b9923e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56eb9ac105e54ee18438b109b6102c98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f53f19346bcc42c29f23fadd77ed8a3f","placeholder":"​","style":"IPY_MODEL_d6d19e5e099d4cb4af08159ecd07d940","value":"Downloading data: 100%"}},"64f5273cb79d4fe8ae0d985ab7b20fb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56eb9ac105e54ee18438b109b6102c98","IPY_MODEL_78ab97f93742417dbccc7a0ebdd7b9c4","IPY_MODEL_fc787e66bb2f435b9062f08a22d5d62e"],"layout":"IPY_MODEL_4e5ba0fbb2274a26b4047ccebf88ef02"}},"65b46a908ccb473bb2bac3527725e8fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b231508b15b440bb3f8a04e4f6eba1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"736221a967cd44588a1628194a096899":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8cac2ecb22874539a8c10f96a036b33a","IPY_MODEL_af6b57a643a94c82a4b85ccbf8d721ba","IPY_MODEL_aaa6aac5144143c69833663d23ea252b"],"layout":"IPY_MODEL_127cca0f1da34a5989861482a9685a22"}},"78ab97f93742417dbccc7a0ebdd7b9c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4360bfc15e484e01a533ac83a13ec8e8","max":657209,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a0b300450e6948f085aacaebc4c14583","value":657209}},"7d72b1d2091a4c42925e3fe507dbf2ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7db56fd7adf240c198584845e6580108":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ff6703b3746485792b2038789972f78":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"845be6c034c24efe8fc8f57fac77bd8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a311d5195264fbda068a581606422db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c58b29fece44ef880bcd92203ed3c8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8cac2ecb22874539a8c10f96a036b33a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12a69edf5e0b4e64bea53d40eb8baf58","placeholder":"​","style":"IPY_MODEL_50604647008f4b9bb3456d6abb93a342","value":"Generating train split: 100%"}},"8fcd5762014e4c16824006371d292d79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"929bd6560db34439a72bbd0666fbc618":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"973b76e1223d409c90b6771a2eafdefc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97998358040a4faca28c0dbb9efca6a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0b300450e6948f085aacaebc4c14583":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a17a6033a2b44f9d94ccc9e43edb311f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17d16550094c4e72847fa2d1ab117cee","IPY_MODEL_3a527ff8d21048199a8ebe2311581304","IPY_MODEL_1adf760cc9a84c188658e6131e078f61"],"layout":"IPY_MODEL_2955ac568e674a35b53f13b78e3d95ad"}},"a3732364853040c0b14fd37ec7d748a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6a9b920a5784667aa49e00364749d7e","placeholder":"​","style":"IPY_MODEL_8c58b29fece44ef880bcd92203ed3c8c","value":" 10.5k/10.5k [00:00&lt;00:00, 349kB/s]"}},"a43025b9f7414f1cb2b1bd4f606a51c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaa6aac5144143c69833663d23ea252b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c02a7a11fd624d1abd74d5df53a81f95","placeholder":"​","style":"IPY_MODEL_7db56fd7adf240c198584845e6580108","value":" 36718/36718 [00:00&lt;00:00, 238150.35 examples/s]"}},"af6b57a643a94c82a4b85ccbf8d721ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3533db5415c84aadb2dc7c6b544741fa","max":36718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18aaf874cf174b1eba37023893d6dc41","value":36718}},"b2fd8dbe431f4971a6a1c7a5b4e32fab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e715ad1d15548de92dcd0ed42f1b625","placeholder":"​","style":"IPY_MODEL_845be6c034c24efe8fc8f57fac77bd8e","value":"Downloading data: 100%"}},"b41c1355dab44561b8e9a2de1604cd59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4800f3c23be48e68b02881923a23dab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b854e0c8127343289acde10732d215c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"babfaefefa9b44578094110addfa4459":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c02a7a11fd624d1abd74d5df53a81f95":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0b9908a8d704ef88a666e06f552d9b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3928ed8d40646208bd02f49fabe3f20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2fd8dbe431f4971a6a1c7a5b4e32fab","IPY_MODEL_45a4a1114106462e845445c47feef65e","IPY_MODEL_135e6fa6fe0641b28d86d399b9f8f577"],"layout":"IPY_MODEL_b854e0c8127343289acde10732d215c1"}},"c4248eaf6f914682a22c1703d75a7383":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc926ae750694229b96946407f776ba8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d1528cca78704db8adb5a59813531f9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6d19e5e099d4cb4af08159ecd07d940":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d97fb3e9e8a74ce1a45d49d4ca923c0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0afb40a516f04a11ab3c5f8edfc1b807","placeholder":"​","style":"IPY_MODEL_6b231508b15b440bb3f8a04e4f6eba1f","value":"Downloading readme: 100%"}},"dd3781e0b42949e3b019dbc8b5341af5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65b46a908ccb473bb2bac3527725e8fa","placeholder":"​","style":"IPY_MODEL_8fcd5762014e4c16824006371d292d79","value":" 3760/3760 [00:00&lt;00:00, 73955.92 examples/s]"}},"dd41194ecb5f4d5fa2b9975ba5035d69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd6ef1b72551453c8d7979a2a6888f27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e23474e123b24f59ae1ad6485dcf79ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e58eef9c9c3b48158b988771fc32307b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_23e0c67c15e24ea195ea0bec1507e610","max":4358,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a311d5195264fbda068a581606422db","value":4358}},"e9b1b14c911742f1b9140f3d7523b9a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea0a7802da244c039d8e00cae9269131":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0b9908a8d704ef88a666e06f552d9b6","max":10464,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc926ae750694229b96946407f776ba8","value":10464}},"f033fd9a698246f99784b7a3e35ff4e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ff6703b3746485792b2038789972f78","max":3760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45a512eacc4d424c86c64da04bb7be61","value":3760}},"f04d1e65a1ec4985bd91df030d71c095":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f746a4c28c4476c981c4bc49f8a088c","IPY_MODEL_e58eef9c9c3b48158b988771fc32307b","IPY_MODEL_2b8bff7537524732982f751a46010a89"],"layout":"IPY_MODEL_22f1f54e147d4d6dadd5f12384c4be4d"}},"f13e9f6d82fe4786ba61e47738c87bca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d97fb3e9e8a74ce1a45d49d4ca923c0b","IPY_MODEL_ea0a7802da244c039d8e00cae9269131","IPY_MODEL_a3732364853040c0b14fd37ec7d748a4"],"layout":"IPY_MODEL_97998358040a4faca28c0dbb9efca6a3"}},"f53f19346bcc42c29f23fadd77ed8a3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6a9b920a5784667aa49e00364749d7e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc787e66bb2f435b9062f08a22d5d62e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19d90a1047924bdc95a0d5bbb9bfe333","placeholder":"​","style":"IPY_MODEL_03be34de531543cd9f476962c93fc4cb","value":" 657k/657k [00:00&lt;00:00, 4.77MB/s]"}}}},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10211,"databundleVersionId":111096,"sourceType":"competition"},{"sourceId":15520,"sourceType":"datasetVersion","datasetId":11167},{"sourceId":38454,"sourceType":"datasetVersion","datasetId":2709}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##As we've seen in the previous sections, tokenization comprises several steps:\n\n##*Normalization (any cleanup of the text that is deemed necessary, such as removing spaces or accents, Unicode normalization, etc.)*\n##*Pre-tokenization (splitting the input into words)*\n##*Running the input through the model (using the pre-tokenized words to produce a sequence of tokens)*\n##*Post-processing (adding the special tokens of the tokenizer, generating the attention mask and token type IDs)*\n##As a reminder, here's another look at the overall process:","metadata":{"id":"pDi7HQla8Lc3"}},{"cell_type":"markdown","source":"##The 🤗 Tokenizers library has been built to provide several options for each of those steps, which you can mix and match together. In this section we'll see how we can build a tokenizer from scratch, as opposed to training a new tokenizer from an old one as we did in section 2. You'll then be able to build any kind of tokenizer you can think of!\n\n##More precisely, the library is built around a central `Tokenizer` class with the building blocks regrouped in submodules:\n\n##*`normalizers` contains all the possible types of `Normalizer` you can use (complete list here[link text](https://huggingface.co/docs/tokenizers/api/normalizers)).*\n##*`pre_tokenizers` contains all the possible types of `PreTokenizer` you can use (complete list here[link text](https://huggingface.co/docs/tokenizers/api/pre-tokenizers)).*\n##*`models` contains the various types of Model you can use, like `BPE, WordPiece, and Unigram`(complete list here[link text](https://huggingface.co/docs/tokenizers/api/models)).*\n##*`trainers` contains all the different types of `Trainer` you can use to train your model on a corpus (one per type of model; complete list here[link text](https://huggingface.co/docs/tokenizers/api/trainers)).*\n##*`post_processors` contains the various types of `PostProcessor` you can use (complete list here[link text](https://huggingface.co/docs/tokenizers/api/post-processors)).*\n##*`decoders` contains the various types of `Decoder` you can use to decode the outputs of tokenization (complete list here[link text](https://huggingface.co/docs/tokenizers/components#decoders)).*\n##You can find the whole list of building blocks here.","metadata":{"id":"Ho92kl-c9cCU"}},{"cell_type":"markdown","source":"#**Acquiring a corpus**#\n##To train our new tokenizer, we will use a small corpus of text (so the examples run fast). The steps for acquiring the corpus are similar to the ones we took at the beginning of this chapter, but this time we'll use the WikiText-2 [link text](https://huggingface.co/datasets/wikitext)dataset:","metadata":{"id":"LLe7LK-eLLRr"}},{"cell_type":"code","source":"!pip install datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15749,"status":"ok","timestamp":1722349535495,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"zgpnoEAKLuDh","outputId":"6cd2f970-e05f-4013-e302-c86999e20b04","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting datasets\n\n  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n\nCollecting pyarrow>=15.0.0 (from datasets)\n\n  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n\nRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n\nCollecting dill<0.3.9,>=0.3.0 (from datasets)\n\n  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n\nCollecting requests>=2.32.2 (from datasets)\n\n  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n\nCollecting xxhash (from datasets)\n\n  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n\nCollecting multiprocess (from datasets)\n\n  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n\nCollecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n\n  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n\nRequirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n\nDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hInstalling collected packages: xxhash, requests, pyarrow, fsspec, dill, multiprocess, datasets\n\n  Attempting uninstall: requests\n\n    Found existing installation: requests 2.31.0\n\n    Uninstalling requests-2.31.0:\n\n      Successfully uninstalled requests-2.31.0\n\n  Attempting uninstall: pyarrow\n\n    Found existing installation: pyarrow 14.0.2\n\n    Uninstalling pyarrow-14.0.2:\n\n      Successfully uninstalled pyarrow-14.0.2\n\n  Attempting uninstall: fsspec\n\n    Found existing installation: fsspec 2024.6.1\n\n    Uninstalling fsspec-2024.6.1:\n\n      Successfully uninstalled fsspec-2024.6.1\n\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n\ntorch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n\ntorch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n\ntorch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n\ntorch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n\ntorch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n\ntorch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n\ntorch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n\ntorch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n\ntorch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n\ntorch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n\ntorch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n\ngcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n\ngoogle-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n\n\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 fsspec-2024.5.0 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 xxhash-3.4.1\n"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"wikitext\",\n                       name=\"wikitext-2-raw-v1\",\n                       split=\"train\")\n\ndef get_training_corpus():\n    # Iterate through the dataset in chunks of 1000\n    for i in range(0, len(dataset), 1000):\n        # Yield a slice of 1000 text entries from the dataset\n        yield dataset[i : i + 1000][\"text\"]\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"executionInfo":{"elapsed":10868,"status":"ok","timestamp":1722350060668,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"pEduuQmHLrol","outputId":"d99afddb-7a7a-4d07-e99e-a87b1d20a64f","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n\nThe secret `HF_TOKEN` does not exist in your Colab secrets.\n\nTo authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n\nYou will be able to reuse this secret in all of your notebooks.\n\nPlease note that authentication is recommended but still optional to access public models or datasets.\n\n  warnings.warn(\n"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f13e9f6d82fe4786ba61e47738c87bca","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a17a6033a2b44f9d94ccc9e43edb311f","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3928ed8d40646208bd02f49fabe3f20","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/6.36M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64f5273cb79d4fe8ae0d985ab7b20fb9","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/657k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f04d1e65a1ec4985bd91df030d71c095","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"736221a967cd44588a1628194a096899","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09dae082821d4ee2acbc9149f469f61f","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"]},"metadata":{}}]},{"cell_type":"markdown","source":"##The function `get_training_corpus()` is a generator that will yield batches of 1,000 texts, which we will use to train the tokenizer.\n\n##🤗 Tokenizers can also be trained on text files directly. Here's how we can generate a text file containing all the texts/inputs from WikiText-2 that we can use locally:","metadata":{"id":"JyfeY5RnN1BA"}},{"cell_type":"code","source":"# Open a file named \"wikitext-2.txt\" in write mode with UTF-8 encoding\nwith open(\"wikitext-2.txt\", \"w\", encoding=\"utf-8\") as f:\n    # Iterate through each item in the dataset\n    for i in range(len(dataset)):\n        # Write the \"text\" field of each dataset item to the file\n        # Add a newline character after each text entry\n        f.write(dataset[i][\"text\"] + \"\\n\")","metadata":{"id":"FqX6QD-NOVHY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#**Building a WordPiece tokenizer from scratch**#\n##To build a tokenizer with the 🤗 Tokenizers library, we start by instantiating a `Tokenizer` object with a `model`, then set its `normalizer, pre_tokenizer, post_processor, and decoder` attributes to the values we want.\n\n##For this example, we'll create a Tokenizer with a WordPiece model:","metadata":{"id":"8U6A3U44PGnL"}},{"cell_type":"code","source":"# Import necessary components from the tokenizers library\nfrom tokenizers import (\n    # Used for decoding tokenized sequences back to text\n    decoders,\n    # Provides various tokenization models\n    models,\n    # Used for text normalization (e.g., lowercase, unicode normalization)\n    normalizers,\n    # Handles initial tokenization steps (e.g., splitting on whitespace)\n    pre_tokenizers,\n    # Processes tokens before and after encoding/decoding\n    processors,\n    # Used for training tokenizer models\n    trainers,\n    # The main Tokenizer class\n    Tokenizer,\n)\n\n# Create a new tokenizer using the WordPiece model\n# WordPiece is a subword tokenization algorithm\n# [UNK] is set as the token for unknown words\ntokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))","metadata":{"id":"7J2d_1o9QpXQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##We have to specify the `unk_token` so the model knows what to return when it encounters characters it hasn't seen before. Other arguments we can set here include the `vocab` of our model (we're going to train the model, so we don't need to set this) and `max_input_chars_per_word`, which specifies a maximum length for each word (words longer than the value passed will be split).\n\n##The first step of tokenization is normalization, so let's begin with that. Since BERT is widely used, there is a `BertNormalizer` with the classic options we can set for BERT: `lowercase and strip_accents`, which are self-explanatory; `clean_text` to remove all control characters and replace repeating spaces with a single one; and `handle_chinese_chars`, which places spaces around Chinese characters. To replicate the `bert-base-uncased` tokenizer, we can just set this normalizer:","metadata":{"id":"4dvmzI-7TJOk"}},{"cell_type":"code","source":"tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)","metadata":{"executionInfo":{"elapsed":1261,"status":"ok","timestamp":1722350346610,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"tYVAUhNaU1O9"},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"##Generally speaking, however, when building a new tokenizer you won't have access to such a handy normalizer already implemented in the 🤗 Tokenizers library -- so let's see how to create the BERT normalizer by hand. The library provides a Lowercase normalizer and a `StripAccents` normalizer, and you can compose several normalizers using a `Sequence`:","metadata":{"id":"oE9GQfu4AOmb"}},{"cell_type":"code","source":"tokenizer.normalizer = normalizers.Sequence(\n        [normalizers.NFD(),\n         normalizers.Lowercase(),\n         normalizers.StripAccents()]\n        )\n","metadata":{"executionInfo":{"elapsed":773,"status":"ok","timestamp":1722350456463,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"qp8bp6M3A-nr"},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"##We're also using an `NFD` Unicode normalizer, as otherwise the `StripAccents` normalizer won't properly recognize the accented characters and thus won't strip them out.\n\n##As we've seen before, we can use the `normalize_str()` method of the `normalizer` to check out the effects it has on a given text:","metadata":{"id":"WoP09do6BUgz"}},{"cell_type":"code","source":"print(tokenizer.normalizer.normalize_str(\"Héllò hôw are ü?\"))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":535,"status":"ok","timestamp":1722350483539,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"guXytVRHCyne","outputId":"3f4f4397-e3f2-4b4a-c363-d3bd32b92ccd"},"execution_count":7,"outputs":[{"name":"stdout","output_type":"stream","text":"hello how are u?\n"}]},{"cell_type":"markdown","source":"##To go further If you test the two versions of the previous normalizers on a string containing the unicode character `u\"\\u0085\"` you will surely notice that these two normalizers are not exactly equivalent. To not over-complicate the version with `normalizers.Sequence` too much , we haven't included the Regex replacements that the `BertNormalizer` requires when the clean_text argument is set to True - which is the default behavior. But don't worry: it is possible to get exactly the same normalization without using the handy BertNormalizer by adding two normalizers.Replace's to the normalizers sequence.\n\n##Next is the pre-tokenization step. Again, there is a prebuilt BertPreTokenizer that we can use:","metadata":{"id":"pfWz31z8e6hB"}},{"cell_type":"code","source":"tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()","metadata":{"executionInfo":{"elapsed":538,"status":"ok","timestamp":1722350531453,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"oG93WUZFfjJa"},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"##Or we can build it from scratch:","metadata":{"id":"GfdhOxoOfsHp"}},{"cell_type":"code","source":"tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()","metadata":{"executionInfo":{"elapsed":481,"status":"ok","timestamp":1722350553038,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"_AS-T0mygvJc"},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"##Note that the Whitespace pre-tokenizer splits on whitespace and all characters that are not letters, digits, or the underscore character, so it technically splits on whitespace and punctuation:","metadata":{"id":"Zj9agkOxg8yJ"}},{"cell_type":"code","source":"tokenizer.pre_tokenizer.pre_tokenize_str(\"Let's test my pre-tokenizer.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":458,"status":"ok","timestamp":1722350584645,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"UMItbYZLhFgB","outputId":"df444081-af86-4b67-ede8-c4e7c3594807"},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":["[('Let', (0, 3)),\n"," (\"'\", (3, 4)),\n"," ('s', (4, 5)),\n"," ('test', (6, 10)),\n"," ('my', (11, 13)),\n"," ('pre', (14, 17)),\n"," ('-', (17, 18)),\n"," ('tokenizer', (18, 27)),\n"," ('.', (27, 28))]"]},"metadata":{}}]},{"cell_type":"markdown","source":"##If you only want to split on whitespace, you should use the `WhitespaceSplit pre-tokenizer` instead:","metadata":{"id":"UXgj9st2hjvt"}},{"cell_type":"code","source":"pre_tokenizer = pre_tokenizers.WhitespaceSplit()\npre_tokenizer.pre_tokenize_str(\"Let's test my pre-tokenizer.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":468,"status":"ok","timestamp":1722350608091,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"rXZYynqmjbeg","outputId":"1303ebde-eabb-4ffd-829f-3c9d0e88be03"},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":["[(\"Let's\", (0, 5)),\n"," ('test', (6, 10)),\n"," ('my', (11, 13)),\n"," ('pre-tokenizer.', (14, 28))]"]},"metadata":{}}]},{"cell_type":"markdown","source":"##Like with normalizers, you can use a `Sequence` to compose several pre-tokenizers:","metadata":{"id":"TcRyX9rGkqzX"}},{"cell_type":"code","source":"pre_tokenizer = pre_tokenizers.Sequence(\n        [pre_tokenizers.WhitespaceSplit(), pre_tokenizers.Punctuation()]\n        )\npre_tokenizer.pre_tokenize_str(\"Let's test my pre-tokenizer.\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":675,"status":"ok","timestamp":1722350648202,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"lUi2OSHvkyfe","outputId":"9253fee8-6e77-41b3-a683-259d8aa9eacb"},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":["[('Let', (0, 3)),\n"," (\"'\", (3, 4)),\n"," ('s', (4, 5)),\n"," ('test', (6, 10)),\n"," ('my', (11, 13)),\n"," ('pre', (14, 17)),\n"," ('-', (17, 18)),\n"," ('tokenizer', (18, 27)),\n"," ('.', (27, 28))]"]},"metadata":{}}]},{"cell_type":"markdown","source":"##The next step in the tokenization pipeline is running the inputs through the model. We already specified our model in the initialization, but we still need to train it, which will require a `WordPieceTrainer`. The main thing to remember when instantiating a trainer in 🤗 Tokenizers is that you need to pass it all the special tokens you intend to use -- otherwise it won't add them to the vocabulary, since they are not in the training corpus:","metadata":{"id":"AZN4NS0BKXrp"}},{"cell_type":"code","source":"# Define a list of special tokens used in many NLP tasks\nspecial_tokens = [\n    #Represents unknown words (words not in the vocabulary)\n    \"[UNK]\",\n    #Used for padding sequences to a fixed length\n    \"[PAD]\",\n    #Typically used at the start of a sequence (e.g., for classification tasks)\n    \"[CLS]\",\n    #Used to separate different parts of a sequence\n    \"[SEP]\",\n    #Used in masked language modeling tasks\n    \"[MASK]\",\n]\n\n# Create a WordPieceTrainer object to train the tokenizer\n# Set the vocabulary size to 25000 words/subwords\n# Include the special tokens defined above\ntrainer = trainers.WordPieceTrainer(vocab_size=25000,\n                                    special_tokens=special_tokens)\n","metadata":{"executionInfo":{"elapsed":738,"status":"ok","timestamp":1722350760907,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"B5bc_s0jKluP"},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"##As well as specifying the `vocab_size` and `special_tokens`, we can set the `min_frequency` (the number of times a token must appear to be included in the vocabulary) or change the `continuing_subword_prefix` (if we want to use something different from `##`).\n\n##To train our model using the iterator we defined earlier, we just have to execute this command:","metadata":{"id":"ANVXp7hJNQTs"}},{"cell_type":"code","source":"tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)","metadata":{"executionInfo":{"elapsed":5403,"status":"ok","timestamp":1722350809591,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"yTO63NT-PK9M"},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"##We can also use text files to train our tokenizer, which would look like this (we reinitialize the model with an empty `WordPiece` beforehand):","metadata":{"id":"Fp3s9UFMQPs0"}},{"cell_type":"code","source":"tokenizer.model = models.WordPiece(unk_token=\"[UNK]\")\ntokenizer.train([\"wikitext-2.txt\"], trainer=trainer)","metadata":{"colab":{"background_save":true},"id":"W7uVRE5HRFO1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##In both cases, we can then test the tokenizer on a text by calling the `encode()` method:","metadata":{"id":"NzPPlvPKRdlT"}},{"cell_type":"code","source":"encoding = tokenizer.encode(\"Let's test this tokenizer.\")\nprint(encoding.tokens)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":524,"status":"ok","timestamp":1722224814783,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"MquaqPTFRoSp","outputId":"fc887205-e800-4c69-ef60-620feefaa4ef"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"['let', \"'\", 's', 'test', 'this', 'tok', '##eni', '##zer', '.']\n"}]},{"cell_type":"markdown","source":"##The `encoding` obtained is an `Encoding`, which contains all the necessary outputs of the tokenizer in its various attributes: `ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, and overflowing`.\n\n##The last step in the tokenization pipeline is post-processing. We need to add the `[CLS]` token at the beginning and the `[SEP]` token at the end (or after each sentence, if we have a pair of sentences). We will use a `TemplateProcessor` for this, but first we need to know the IDs of the `[CLS] and [SEP]` tokens in the vocabulary:","metadata":{"id":"CeCoqeAVnD3G"}},{"cell_type":"code","source":"# Get the ID of the [CLS] token from the tokenizer\ncls_token_id = tokenizer.token_to_id(\"[CLS]\")\n\n# Get the ID of the [SEP] token from the tokenizer\nsep_token_id = tokenizer.token_to_id(\"[SEP]\")\n\n# Print the IDs of the [CLS] and [SEP] tokens\nprint(cls_token_id, sep_token_id)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":693,"status":"ok","timestamp":1722225482736,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"nv7ikTzqnyHp","outputId":"c373a225-d2c1-4e3e-8446-90c9bffc454a"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"2 3\n"}]},{"cell_type":"markdown","source":"##To write the template for the `TemplateProcessor`, we have to specify how to treat a single sentence and a pair of sentences. For both, we write the special tokens we want to use; the `first (or single) sentence is represented by $A`, while the `second sentence (if encoding a pair) is represented by $B`. For each of these (special tokens and sentences), we also specify the corresponding token type ID after a colon.\n\n##The classic BERT template is thus defined as follows:","metadata":{"id":"qzadO_5xpPme"}},{"cell_type":"code","source":"# Set up the post-processor for the tokenizer\ntokenizer.post_processor = processors.TemplateProcessing(\n    # Template for single sequence: [CLS] at start, then the sequence, then [SEP]\n    single=f\"[CLS]:0 $A:0 [SEP]:0\",\n\n    # Template for pair of sequences: [CLS], first sequence, [SEP], second sequence, [SEP]\n    pair=f\"[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1\",\n\n    # Define the special tokens and their IDs\n        special_tokens=[(\"[CLS]\", cls_token_id), (\"[SEP]\", sep_token_id)],\n\n)","metadata":{"id":"nyNiDWbNqxaI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Note that we need to pass along the IDs of the special tokens, so the tokenizer can properly convert them to their IDs.\n\n##Once this is added, going back to our previous example will give:","metadata":{"id":"3q_2gRWosyE0"}},{"cell_type":"code","source":"encoding = tokenizer.encode(\"Let's test this tokenizer.\")\nprint(encoding.tokens)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":719,"status":"ok","timestamp":1722226566843,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"9YSjvb0zs8ZT","outputId":"4b261f44-11e7-4b96-d1cc-0c573735e6e1"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"['[CLS]', 'let', \"'\", 's', 'test', 'this', 'tok', '##eni', '##zer', '.', '[SEP]']\n"}]},{"cell_type":"markdown","source":"##And on a pair of sentences, we get the proper result:","metadata":{"id":"2-v4knXptFwS"}},{"cell_type":"code","source":"encoding = tokenizer.encode(\"Let's test this tokenizer...\", \"on a pair of sentences.\")\nprint(encoding.tokens)\nprint(encoding.type_ids)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":525,"status":"ok","timestamp":1722226912071,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"},"user_tz":-120},"id":"HlitkiT1uOyk","outputId":"93803b0c-55a7-4ed3-e387-a41675878adc"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"['[CLS]', 'let', \"'\", 's', 'test', 'this', 'tok', '##eni', '##zer', '...', '[SEP]', 'on', 'a', 'pair', 'of', 'sentences', '.', '[SEP]']\n\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n"}]},{"cell_type":"markdown","source":"##We've almost finished building this tokenizer from scratch -- the last step is to include a decoder:","metadata":{"id":"GS9Ynw0xvH0T"}},{"cell_type":"code","source":"tokenizer.decoder = decoders.WordPiece(prefix=\"##\")","metadata":{"id":"iqogqUP3vPZ_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Let's test it on our previous encoding:","metadata":{"id":"XdH8_Ytn6PGC"}},{"cell_type":"code","source":"tokenizer.decode(encoding.ids)","metadata":{"id":"sSCgX7l16Tb3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Great! We can save our tokenizer in a single JSON file like this:","metadata":{"id":"hR_lpzgg6XaH"}},{"cell_type":"code","source":"tokenizer.save(\"tokenizer.json\")","metadata":{"id":"ovQIoonQ6bR2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##We can then reload that file in a `Tokenizer` object with the `from_file()` method:","metadata":{"id":"JJiaGv9S6gcd"}},{"cell_type":"code","source":"new_tokenizer = Tokenizer.from_file(\"tokenizer.json\")","metadata":{"id":"hYK3ZjlE6oS2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#×To use this tokenizer in 🤗 Transformers, we have to wrap it in a `PreTrainedTokenizerFast`. We can either use the generic class or, if our tokenizer corresponds to an existing model, use that class (here,` BertTokenizerFast`). If you apply this lesson to build a brand new tokenizer, you will have to use the first option.\n\n##To wrap the tokenizer in a PreTrainedTokenizerFast, we can either pass the tokenizer we built as a tokenizer_object or pass the tokenizer file we saved as tokenizer_file. The key thing to remember is that we have to manually set all the special tokens, since that class can't infer from the tokenizer object which token is the mask token, the [CLS] token, etc.:","metadata":{"id":"jkyLFqYX6vYj"}},{"cell_type":"code","source":"from transformers import PreTrainedTokenizerFast\n\nwrapped_tokenizer = PreTrainedTokenizerFast(\n    tokenizer_object=tokenizer,\n    # tokenizer_file=\"tokenizer.json\", # You can load from the tokenizer file, alternatively\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    cls_token=\"[CLS]\",\n    sep_token=\"[SEP]\",\n    mask_token=\"[MASK]\",\n)","metadata":{"id":"K8u8gQiQ7Gj4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##If you are using a specific tokenizer class (like BertTokenizerFast), you will only need to specify the special tokens that are different from the default ones (here, none):","metadata":{"id":"FseKgDCj7dcg"}},{"cell_type":"code","source":"from transformers import BertTokenizerFast\n\nwrapped_tokenizer = BertTokenizerFast(tokenizer_object=tokenizer)","metadata":{"id":"W00Hnppn7in1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##You can then use this tokenizer like any other 🤗 Transformers tokenizer. You can save it with the `save_pretrained()` method, or upload it to the Hub with the `push_to_hub()1 method.\n\n##Now that we've seen how to build a WordPiece tokenizer, let's do the same for a BPE tokenizer. We'll go a bit faster since you know all the steps, and only highlight the differences.","metadata":{"id":"Kab_N5557rsi"}},{"cell_type":"markdown","source":"#**Building a BPE tokenizer from scratch**#\n##Let's now build a GPT-2 tokenizer. Like for the BERT tokenizer, we start by initializing a Tokenizer with a BPE model:","metadata":{"id":"jl5N35Sq76eH"}},{"cell_type":"code","source":"tokenizer = Tokenizer(models.BPE())","metadata":{"id":"-4L1N2pu8GMy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Also like for BERT, we could initialize this model with a vocabulary if we had one (we would need to pass the vocab and merges in this case), but since we will train from scratch, we don't need to do that. We also don't need to specify an unk_token because GPT-2 uses byte-level BPE, which doesn't require it.\n\n##GPT-2 does not use a normalizer, so we skip that step and go directly to the pre-tokenization:","metadata":{"id":"Vh9BpJx78NnG"}},{"cell_type":"code","source":"tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)","metadata":{"id":"Scvtn_-g8Ufk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##The option we added to ByteLevel here is to not add a space at the beginning of a sentence (which is the default otherwise). We can have a look at the pre-tokenization of an example text like before:","metadata":{"id":"7p8-4arb8ZuE"}},{"cell_type":"code","source":"tokenizer.pre_tokenizer.pre_tokenize_str(\"Let's test pre-tokenization!\")","metadata":{"id":"nrN8PM9p8eQn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Next is the model, which needs training. For GPT-2, the only special token is the end-of-text token:","metadata":{"id":"Cx2mbuEG8jdE"}},{"cell_type":"code","source":"trainer = trainers.BpeTrainer(vocab_size=25000, special_tokens=[\"<|endoftext|>\"])\ntokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)","metadata":{"id":"aVKebqH38nwK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Like with the `WordPieceTrainer`, as well as the `vocab_size` and `special_tokens`, we can specify the `min_frequency` if we want to, or if we have an `end-of-word suffix (like </w>)`, we can set it with end_of_word_suffix.\n\n##This tokenizer can also be trained on text files:","metadata":{"id":"desQBUpT8upq"}},{"cell_type":"code","source":"tokenizer.model = models.BPE()\ntokenizer.train([\"wikitext-2.txt\"], trainer=trainer)","metadata":{"id":"aD6GjPY69BKs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Let's have a look at the tokenization of a sample text:","metadata":{"id":"8-YBp0QL9GsW"}},{"cell_type":"code","source":"encoding = tokenizer.encode(\"Let's test this tokenizer.\")\nprint(encoding.tokens)","metadata":{"id":"PV5fMGVO9LKL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##We apply the byte-level post-processing for the GPT-2 tokenizer as follows:","metadata":{"id":"omdi0E_l9YCe"}},{"cell_type":"code","source":"tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)","metadata":{"id":"xLbRTpHj9dH0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##The `trim_offsets = False` option indicates to the post-processor that we should leave the offsets of tokens that begin with 'Ġ' as they are: this way the start of the offsets will point to the space before the word, not the first character of the word (since the space is technically part of the token). Let's have a look at the result with the text we just encoded, where `'Ġtest'` is the token at index 4:","metadata":{"id":"uWLt4Ze49iZk"}},{"cell_type":"code","source":"sentence = \"Let's test this tokenizer.\"\nencoding = tokenizer.encode(sentence)\nstart, end = encoding.offsets[4]\nsentence[start:end]","metadata":{"id":"nE9qzeFi90ex"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Finally, we add a byte-level decoder:","metadata":{"id":"JmUpjEC3-A_0"}},{"cell_type":"code","source":"tokenizer.decoder = decoders.ByteLevel()","metadata":{"id":"-qopzC3r-NB3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##and we can double-check it works properly:","metadata":{"id":"Tyf3L8q2-RpE"}},{"cell_type":"code","source":"tokenizer.decode(encoding.ids)","metadata":{"id":"Now7qST2-a5i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Great! Now that we're done, we can save the tokenizer like before, and wrap it in a `PreTrainedTokenizerFast or GPT2TokenizerFast` if we want to use it in 🤗 Transformers:","metadata":{"id":"uor2fmTZ-gSl"}},{"cell_type":"code","source":"from transformers import PreTrainedTokenizerFast\n\nwrapped_tokenizer = PreTrainedTokenizerFast(\n    tokenizer_object=tokenizer,\n    bos_token=\"<|endoftext|>\",\n    eos_token=\"<|endoftext|>\",\n            )","metadata":{"id":"jKjywSEGt4yd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"OR:","metadata":{"id":"zRVw7m-HuBbp"}},{"cell_type":"code","source":"from transformers import GPT2TokenizerFast\n\nwrapped_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)","metadata":{"id":"3DWeV3r3uIWu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#**Building a Unigram tokenizer from scratch**#\n##Let's now build an XLNet tokenizer. Like for the previous tokenizers, we start by initializing a Tokenizer with a Unigram model:","metadata":{"id":"wxNx-CSLuSio"}},{"cell_type":"code","source":"tokenizer = Tokenizer(models.Unigram())","metadata":{"id":"AZ5WJJcrumU7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Again, we could initialize this model with a vocabulary if we had one.\n\n##For the normalization, XLNet uses a few replacements (which come from SentencePiece):","metadata":{"id":"6-oT0b8wutcd"}},{"cell_type":"code","source":"from tokenizers import Regex\n\ntokenizer.normalizer = normalizers.Sequence(\n    [# Replace double backticks with double quotes\n     normalizers.Replace(\"``\", '\"'),\n     # Replace double single quotes with double quotes\n     normalizers.Replace(\"''\", '\"'),\n     # Apply Unicode normalization (decomposition)\n     normalizers.NFKD(),\n     # Remove accents from characters\n     normalizers.StripAccents(),\n     # Replace multiple spaces with a single space\n     normalizers.Replace(Regex(\" {2,}\"), \" \"),]\n    )","metadata":{"id":"MxkYJhtPvpGT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##This replaces `` and '' with \" and any sequence of two or more spaces with a single space, as well as removing the accents in the texts to tokenize.\n\n##The pre-tokenizer to use for any SentencePiece tokenizer is `Metaspace`:","metadata":{"id":"G9tf7TSzw-pr"}},{"cell_type":"code","source":"tokenizer.pre_tokenizer = pre_tokenizers.Metaspace()","metadata":{"id":"j8MM4YDIxLzM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##We can have a look at the pre-tokenization of an example text like before:","metadata":{"id":"vXnmYxZMxRjf"}},{"cell_type":"code","source":"tokenizer.pre_tokenizer.pre_tokenize_str(\"Let's test the pre-tokenizer!\")","metadata":{"id":"Rdi81nhWxVkr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Next is the model, which needs training. XLNet has quite a few special tokens:","metadata":{"id":"0lHeuQxzxZau"}},{"cell_type":"code","source":"special_tokens = [\"<cls>\",\n                  \"<sep>\",\n                  \"<unk>\",\n                  \"<pad>\",\n                  \"<mask>\",\n                  \"<s>\",\n                  \"</s>\"]\n\ntrainer = trainers.UnigramTrainer(\n    vocab_size=25000,\n    special_tokens=special_tokens,\n    unk_token=\"<unk>\"\n)\n\ntokenizer.train_from_iterator(get_training_corpus(),\n                              trainer=trainer)","metadata":{"id":"KspQ9JggxiVN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##A very important argument not to forget for the `UnigramTrainer` is the `unk_token`. We can also pass along other arguments specific to the Unigram algorithm, such as the `shrinking_factor` for each step where we remove tokens (defaults to 0.75) or the `max_piece_length` to specify the maximum length of a given token (defaults to 16).\n\n##This tokenizer can also be trained on text files:","metadata":{"id":"cODQYPz6yg0C"}},{"cell_type":"code","source":"tokenizer.model = models.Unigram()\ntokenizer.train([\"wikitext-2.txt\"], trainer=trainer)","metadata":{"id":"_EsiBBZyzaB5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Let's have a look at the tokenization of a sample text:","metadata":{"id":"AHfItbl0zd6v"}},{"cell_type":"markdown","source":"##A peculiarity of XLNet is that it puts the `<cls>` token at the end of the sentence, with a type ID of 2 (to distinguish it from the other tokens). It's padding on the left, as a result. We can deal with all the special tokens and token type IDs with a template, like for BERT, but first we have to get the IDs of the `<cls>` and `<sep>` tokens:","metadata":{"id":"X9K0SLZBz1M0"}},{"cell_type":"code","source":"cls_token_id = tokenizer.token_to_id(\"<cls>\")\nsep_token_id = tokenizer.token_to_id(\"<sep>\")\nprint(cls_token_id, sep_token_id)","metadata":{"id":"gAxxhj-R0UBs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##The template looks like this:","metadata":{"id":"kAszAHEm0cu4"}},{"cell_type":"code","source":"tokenizer.post_processor = processors.TemplateProcessing(\n        single=\"$A:0 <sep>:0 <cls>:2\",\n        pair=\"$A:0 <sep>:0 $B:1 <sep>:1 <cls>:2\",\n        special_tokens=[(\"<sep>\", sep_token_id), (\"<cls>\", cls_token_id)],\n                )\n","metadata":{"id":"yuAoaETr1LnR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##And we can test it works by encoding a pair of sentences:","metadata":{"id":"8QcbjF991U9N"}},{"cell_type":"code","source":"encoding = tokenizer.encode(\"Let's test this tokenizer...\", \"on a pair of sentences!\")\nprint(encoding.tokens)\nprint(encoding.type_ids)","metadata":{"id":"-9FCcx6m1dlY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Finally, we add a Metaspace decoder:","metadata":{"id":"4Tta0dtt11KH"}},{"cell_type":"code","source":"tokenizer.decoder = decoders.Metaspace()","metadata":{"id":"eDoc3oUn15uX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##and we're done with this tokenizer! We can save the tokenizer like before, and wrap it in a `PreTrainedTokenizerFast` or `XLNetTokenizerFast` if we want to use it in 🤗 Transformers. One thing to note when using `PreTrainedTokenizerFast` is that on top of the special tokens, we need to tell the 🤗 Transformers library to pad on the left:","metadata":{"id":"pchh0acb2FpC"}},{"cell_type":"code","source":"from transformers import PreTrainedTokenizerFast\n\nwrapped_tokenizer = PreTrainedTokenizerFast(\n    tokenizer_object=tokenizer,\n    bos_token=\"<s>\",\n    eos_token=\"</s>\",\n    unk_token=\"<unk>\",\n    pad_token=\"<pad>\",\n    cls_token=\"<cls>\",\n    sep_token=\"<sep>\",\n    mask_token=\"<mask>\",\n    padding_side=\"left\",\n)","metadata":{"id":"OVVMR5K72a6g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##Or alternatively:","metadata":{"id":"RS4zJmFR2072"}},{"cell_type":"code","source":"from transformers import XLNetTokenizerFast\n\nwrapped_tokenizer = XLNetTokenizerFast(tokenizer_object=tokenizer)","metadata":{"id":"MHI8jiv124uu"},"execution_count":null,"outputs":[]}]}