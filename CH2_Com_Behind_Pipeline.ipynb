{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPXCwHR/mliYiZNQK01nejf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6e17e5818a5e41a6839c4ab78385e3b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30c0d7d8c6e34e8d93902a445bc6f6c0","IPY_MODEL_529c1557289d428e857db9a2a742290c","IPY_MODEL_f87ce60860a440bd8537e616c822cf1f"],"layout":"IPY_MODEL_60679a9b00c94ef6ab33f8503d226bf2"}},"30c0d7d8c6e34e8d93902a445bc6f6c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_faba75b4d0f6471f8c8e340b002ea714","placeholder":"​","style":"IPY_MODEL_fd501224de07425ca0ea45ef7ffcd91e","value":"config.json: 100%"}},"529c1557289d428e857db9a2a742290c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d01f07dbc8af4b23b25d3e5a5aa108bb","max":629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_626f2ce96f1641ccb78599a69ac835de","value":629}},"f87ce60860a440bd8537e616c822cf1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48edc9b4d7cf4f6f88ee9ca9ee066112","placeholder":"​","style":"IPY_MODEL_3a6d65434142402c858264b920a4156f","value":" 629/629 [00:00&lt;00:00, 21.9kB/s]"}},"60679a9b00c94ef6ab33f8503d226bf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"faba75b4d0f6471f8c8e340b002ea714":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd501224de07425ca0ea45ef7ffcd91e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d01f07dbc8af4b23b25d3e5a5aa108bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"626f2ce96f1641ccb78599a69ac835de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"48edc9b4d7cf4f6f88ee9ca9ee066112":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a6d65434142402c858264b920a4156f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38071da472a8494aa38b0a0ba7ca638b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc420ebe961140f5b7e6119760642780","IPY_MODEL_9d72b9eebdd8484384aab0889dd7ec36","IPY_MODEL_63812db4482b440eac5398412d6acbce"],"layout":"IPY_MODEL_227fe9bb7b5e4d24bd42f0254221f88b"}},"dc420ebe961140f5b7e6119760642780":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bc9d20ce0454535b1043a36b19f7acc","placeholder":"​","style":"IPY_MODEL_1ea9b775420c4e2b9a05d0fbdd7a5d8b","value":"model.safetensors: 100%"}},"9d72b9eebdd8484384aab0889dd7ec36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27f8845b910b497e800e73ed054d429c","max":267832558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d6ad8439c6ac423fa000748bece43324","value":267832558}},"63812db4482b440eac5398412d6acbce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4326c5c401c4898ba8cbfb6ec086ccd","placeholder":"​","style":"IPY_MODEL_f0dfd8355af447838ce193e180ad7340","value":" 268M/268M [00:02&lt;00:00, 139MB/s]"}},"227fe9bb7b5e4d24bd42f0254221f88b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bc9d20ce0454535b1043a36b19f7acc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ea9b775420c4e2b9a05d0fbdd7a5d8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27f8845b910b497e800e73ed054d429c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6ad8439c6ac423fa000748bece43324":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4326c5c401c4898ba8cbfb6ec086ccd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0dfd8355af447838ce193e180ad7340":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"344ac9cf24894f66b508eb5aef8c934a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_76f9f04f5f9849679baf22c5b3542ddb","IPY_MODEL_bd8fbaa1c9cf4321bfe6e6078bbe3274","IPY_MODEL_05f8811e132b446a812bceea65f181c8"],"layout":"IPY_MODEL_b5329605dcc1422ba874c8ab4133a46c"}},"76f9f04f5f9849679baf22c5b3542ddb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb0f2aaaa6e44324b3869e74c2bdce8c","placeholder":"​","style":"IPY_MODEL_190c0928b2c84470ad48029f5994c811","value":"tokenizer_config.json: 100%"}},"bd8fbaa1c9cf4321bfe6e6078bbe3274":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_54c4501ad471400ebdeb43f63e8fdc95","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f47febc6af354bacac525feecc3fa53a","value":48}},"05f8811e132b446a812bceea65f181c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaa5b134965446a79aae2a57554529d9","placeholder":"​","style":"IPY_MODEL_bc0a1a7d206a4ac5825a1509417e3ad3","value":" 48.0/48.0 [00:00&lt;00:00, 2.41kB/s]"}},"b5329605dcc1422ba874c8ab4133a46c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb0f2aaaa6e44324b3869e74c2bdce8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"190c0928b2c84470ad48029f5994c811":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54c4501ad471400ebdeb43f63e8fdc95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f47febc6af354bacac525feecc3fa53a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eaa5b134965446a79aae2a57554529d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc0a1a7d206a4ac5825a1509417e3ad3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9347ee2aa4914e8b9aaf006201c3d116":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd2ebbec8e8f44169dbd24a3d132edfd","IPY_MODEL_f82c2108f6714baaa44cb7db85df095c","IPY_MODEL_840f4aacdf0d4bac97d79c0477c1b600"],"layout":"IPY_MODEL_3d8439e7a34d46deb9f0c75c907ddf93"}},"bd2ebbec8e8f44169dbd24a3d132edfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b64fcedf99ba4103b7bd4fc4b1dbd488","placeholder":"​","style":"IPY_MODEL_8dbc33147e2d42efb8a331358f3c41d4","value":"vocab.txt: 100%"}},"f82c2108f6714baaa44cb7db85df095c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38ac59f231924f92acbd36b1fb627350","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8665ef5b31ef423d9e0f1b1c196da94f","value":231508}},"840f4aacdf0d4bac97d79c0477c1b600":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54b74a60a75e4398965f224b46c577a5","placeholder":"​","style":"IPY_MODEL_6cf502909e464282a198b0429e5df522","value":" 232k/232k [00:00&lt;00:00, 3.10MB/s]"}},"3d8439e7a34d46deb9f0c75c907ddf93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b64fcedf99ba4103b7bd4fc4b1dbd488":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dbc33147e2d42efb8a331358f3c41d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38ac59f231924f92acbd36b1fb627350":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8665ef5b31ef423d9e0f1b1c196da94f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54b74a60a75e4398965f224b46c577a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cf502909e464282a198b0429e5df522":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93fdb76ec2394f22af2c466cade22fba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46ce3aa3bc4f4fb4b833ced41cf26443","IPY_MODEL_56839213a95a493dbf227cb70cc5bcf4","IPY_MODEL_b8806db47e414ab5b897b31f4b228ba7"],"layout":"IPY_MODEL_60811ffa71ff46deb29b2d9ad02916c3"}},"46ce3aa3bc4f4fb4b833ced41cf26443":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a18b2b3fe1c43588614a25813226ebd","placeholder":"​","style":"IPY_MODEL_c6d4a6a693854dfa9df0946a734ae0b0","value":"tokenizer_config.json: 100%"}},"56839213a95a493dbf227cb70cc5bcf4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6d3fb2d52d147e0a3cf83c18a039a74","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_253557115a78448db759d131c8f9c6d8","value":48}},"b8806db47e414ab5b897b31f4b228ba7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26f02d8c4fe848cdb9c8642b3acc7a4b","placeholder":"​","style":"IPY_MODEL_ae74c987a12d407b8bdec697d0b637a5","value":" 48.0/48.0 [00:00&lt;00:00, 1.88kB/s]"}},"60811ffa71ff46deb29b2d9ad02916c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a18b2b3fe1c43588614a25813226ebd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6d4a6a693854dfa9df0946a734ae0b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6d3fb2d52d147e0a3cf83c18a039a74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"253557115a78448db759d131c8f9c6d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26f02d8c4fe848cdb9c8642b3acc7a4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae74c987a12d407b8bdec697d0b637a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cd414b4aabd4908a48098aa8f6dcb5a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5689ca4575cb40939ce333714cb6d4d9","IPY_MODEL_48dc14cca17f4efeb73ffb2bb360f348","IPY_MODEL_49ee1e0e20444729967756377f7bee9b"],"layout":"IPY_MODEL_1ed65358abcc46fdb136258adf0e3f28"}},"5689ca4575cb40939ce333714cb6d4d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0556fd93b37447fbe5b96c36ccfd469","placeholder":"​","style":"IPY_MODEL_05893daa12104670ab98f03ea7259f2c","value":"config.json: 100%"}},"48dc14cca17f4efeb73ffb2bb360f348":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80c5052ce18b45b3bb22e58882d9c347","max":629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e4b1a9e5149432d96919a2cde7ebf0e","value":629}},"49ee1e0e20444729967756377f7bee9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53955d5d23f143669573495054df5da7","placeholder":"​","style":"IPY_MODEL_fc9e71585695473fb56ee75e2bede6de","value":" 629/629 [00:00&lt;00:00, 19.6kB/s]"}},"1ed65358abcc46fdb136258adf0e3f28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0556fd93b37447fbe5b96c36ccfd469":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05893daa12104670ab98f03ea7259f2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80c5052ce18b45b3bb22e58882d9c347":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e4b1a9e5149432d96919a2cde7ebf0e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53955d5d23f143669573495054df5da7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc9e71585695473fb56ee75e2bede6de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d820e2194864c9cb567b789ccc8a522":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b7ab2303a7648e29268fff2142773ac","IPY_MODEL_95be901b752f41f98c65996033373618","IPY_MODEL_34e071be2cde4b9788b7d6e84dec5a86"],"layout":"IPY_MODEL_452ed71aa6394d70b15492e76adca507"}},"6b7ab2303a7648e29268fff2142773ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe4eea21c22e4d7a93bf32c9cbbaf850","placeholder":"​","style":"IPY_MODEL_86ef1151372045fda16732d23407cc9e","value":"vocab.txt: 100%"}},"95be901b752f41f98c65996033373618":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30e0a561086247d09f797dee7bfd0d5c","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d709f007f50544038b275a7a9c677e6d","value":231508}},"34e071be2cde4b9788b7d6e84dec5a86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a140dccd59c84c9eb79dfcd7ab183ff5","placeholder":"​","style":"IPY_MODEL_0398dfba7efd4a389a56440af5df9b30","value":" 232k/232k [00:00&lt;00:00, 6.00MB/s]"}},"452ed71aa6394d70b15492e76adca507":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe4eea21c22e4d7a93bf32c9cbbaf850":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86ef1151372045fda16732d23407cc9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30e0a561086247d09f797dee7bfd0d5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d709f007f50544038b275a7a9c677e6d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a140dccd59c84c9eb79dfcd7ab183ff5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0398dfba7efd4a389a56440af5df9b30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00378ba3f95f449ea528b1e526dc1741":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_438a92f95efa4be39e8bdc0e1aa1fc7d","IPY_MODEL_b57df1200eae4e3483e57d377615b0fd","IPY_MODEL_1b75b6d0757946018c19a4e19d70288b"],"layout":"IPY_MODEL_4d4a4afd0820405992558636d7f55ee6"}},"438a92f95efa4be39e8bdc0e1aa1fc7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_770126632f524a51ba3ce0a18596fe84","placeholder":"​","style":"IPY_MODEL_a535e84bedbe4fd3af24642dc8063299","value":"model.safetensors: 100%"}},"b57df1200eae4e3483e57d377615b0fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab1ec09fa5ff432ea76dc738c9f8e1bb","max":267832558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85573e7f5fa14062a0c930caa0eac95b","value":267832558}},"1b75b6d0757946018c19a4e19d70288b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f334b755a4f425c9729f0bfd8e0171f","placeholder":"​","style":"IPY_MODEL_fc6979bf718b4965bb3f8e0a40db6361","value":" 268M/268M [00:03&lt;00:00, 103MB/s]"}},"4d4a4afd0820405992558636d7f55ee6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"770126632f524a51ba3ce0a18596fe84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a535e84bedbe4fd3af24642dc8063299":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab1ec09fa5ff432ea76dc738c9f8e1bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85573e7f5fa14062a0c930caa0eac95b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f334b755a4f425c9729f0bfd8e0171f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc6979bf718b4965bb3f8e0a40db6361":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eaf07a98715443aaa6a06c1cf7fc9ddf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07025233dc9b49b29faf20d1f29241aa","IPY_MODEL_e8fa149f0561419f8ac6eebf41f90db9","IPY_MODEL_e97d8b28734047bd818a3184f567b90d"],"layout":"IPY_MODEL_e846c597c28f4abaa1b1a8ad8fe1fd3c"}},"07025233dc9b49b29faf20d1f29241aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5d33b29996241f6b4503a1ab001b991","placeholder":"​","style":"IPY_MODEL_2067c6e1bacd4e1e997b33dec04dde1d","value":"config.json: 100%"}},"e8fa149f0561419f8ac6eebf41f90db9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67aadc5831d842b1af8fe7ed4b2ef877","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b490a1edd1c4c118bc5f1175d092196","value":570}},"e97d8b28734047bd818a3184f567b90d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ce5f2c495c04a99bf47b0a3de7ac6c3","placeholder":"​","style":"IPY_MODEL_dbc3ca4d204843d8947b9f166a236808","value":" 570/570 [00:00&lt;00:00, 11.3kB/s]"}},"e846c597c28f4abaa1b1a8ad8fe1fd3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5d33b29996241f6b4503a1ab001b991":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2067c6e1bacd4e1e997b33dec04dde1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67aadc5831d842b1af8fe7ed4b2ef877":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b490a1edd1c4c118bc5f1175d092196":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ce5f2c495c04a99bf47b0a3de7ac6c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbc3ca4d204843d8947b9f166a236808":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e0c7ed185374e63a7cf6822d7c32a8c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b238707e19d7405fa769ad4d39909115","IPY_MODEL_e9d458a831bd4de68487578636d36e55","IPY_MODEL_6578cb2736fa45ccbbc134f65c308b87"],"layout":"IPY_MODEL_9776138890da42d2a7fc6a5852915d79"}},"b238707e19d7405fa769ad4d39909115":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a20414a36fd4bd5ba391e0507cccdfe","placeholder":"​","style":"IPY_MODEL_038ab46b57da48c38fda58f907ee44e1","value":"model.safetensors: 100%"}},"e9d458a831bd4de68487578636d36e55":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_54cc80267b6f4f6ea7fae8f4a6c1dd23","max":435755784,"min":0,"orientation":"horizontal","style":"IPY_MODEL_34d82571367740aa9bb73d9b88e36ae7","value":435755784}},"6578cb2736fa45ccbbc134f65c308b87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c3beaa7960a42728dbb7f63e34bcd61","placeholder":"​","style":"IPY_MODEL_77b304953bf74d1780aa18573737a31d","value":" 436M/436M [00:06&lt;00:00, 114MB/s]"}},"9776138890da42d2a7fc6a5852915d79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a20414a36fd4bd5ba391e0507cccdfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"038ab46b57da48c38fda58f907ee44e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54cc80267b6f4f6ea7fae8f4a6c1dd23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34d82571367740aa9bb73d9b88e36ae7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c3beaa7960a42728dbb7f63e34bcd61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77b304953bf74d1780aa18573737a31d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95948ee246774ca980060910686b1028":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4a7c64decf4c49419ccd17ec9f739ea5","IPY_MODEL_8d517c9ef4b3472eba2c3c55b50cc455","IPY_MODEL_5ba04d1c243d4e34a32ad0fcf0fdb3e7"],"layout":"IPY_MODEL_ae78cc09b5514047aed585f94dd5f6b1"}},"4a7c64decf4c49419ccd17ec9f739ea5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2947503a6dc8496bbc1133bb5ce9df41","placeholder":"​","style":"IPY_MODEL_9d56542abdb840f9a30bb09437576bae","value":"tokenizer_config.json: 100%"}},"8d517c9ef4b3472eba2c3c55b50cc455":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f96a5180825f4c70b2e7e028b052bb5d","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08383b886ca04b6fa38eca0dca69282b","value":49}},"5ba04d1c243d4e34a32ad0fcf0fdb3e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b878cce7ead4e728e1f7dca88f287b5","placeholder":"​","style":"IPY_MODEL_a27a806b9b3c4c209d3e7963ea96eb3a","value":" 49.0/49.0 [00:00&lt;00:00, 1.24kB/s]"}},"ae78cc09b5514047aed585f94dd5f6b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2947503a6dc8496bbc1133bb5ce9df41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d56542abdb840f9a30bb09437576bae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f96a5180825f4c70b2e7e028b052bb5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08383b886ca04b6fa38eca0dca69282b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b878cce7ead4e728e1f7dca88f287b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a27a806b9b3c4c209d3e7963ea96eb3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d828d16be34e42cab1b085dbabfba3c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba67d2db9a054d99bd66aebad0ed3705","IPY_MODEL_00d579fe48c74f8f964a5e59201f1bd9","IPY_MODEL_a0be4afc2b5c4d1faad20ae8b1e0f6e8"],"layout":"IPY_MODEL_5ad67aa415e3423aa05280359d289650"}},"ba67d2db9a054d99bd66aebad0ed3705":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a2e49fa62184b3d84acc2e6f236c35b","placeholder":"​","style":"IPY_MODEL_ab1b101b6c944b239ade4e182a6c9519","value":"vocab.txt: 100%"}},"00d579fe48c74f8f964a5e59201f1bd9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbef4ed937af4af1991d1501fa90f11d","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac153a59e71e44ffbc3763c08e62a34c","value":213450}},"a0be4afc2b5c4d1faad20ae8b1e0f6e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58983126efdd4079a6e8913d8e9e614a","placeholder":"​","style":"IPY_MODEL_fe4d789a24454d709c390282e46c656f","value":" 213k/213k [00:00&lt;00:00, 2.11MB/s]"}},"5ad67aa415e3423aa05280359d289650":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a2e49fa62184b3d84acc2e6f236c35b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab1b101b6c944b239ade4e182a6c9519":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbef4ed937af4af1991d1501fa90f11d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac153a59e71e44ffbc3763c08e62a34c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58983126efdd4079a6e8913d8e9e614a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe4d789a24454d709c390282e46c656f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f8756c7f8b24f918a651b9ce5aa0d72":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e38fbb79eb345e8aa8175fbd527c327","IPY_MODEL_98b4c1814ff145818b6df8ca334a0e4b","IPY_MODEL_3ff342c5f2cb4cd1a9f6e9815a3d69af"],"layout":"IPY_MODEL_2ca4df7c9e4f4a0abe82ea90c2007e45"}},"4e38fbb79eb345e8aa8175fbd527c327":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c1fcfdefea449cf928681797d6bab76","placeholder":"​","style":"IPY_MODEL_ba554a1772da4784a80820e97f5d1a86","value":"tokenizer.json: 100%"}},"98b4c1814ff145818b6df8ca334a0e4b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0fbb3f18d00441789aca756b0faa2ee","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b95c180aa7c3426d821a5a20abe2987b","value":435797}},"3ff342c5f2cb4cd1a9f6e9815a3d69af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4aecf4ee3a64f3d9bba525fe0e418c5","placeholder":"​","style":"IPY_MODEL_d9e128545e984d27876919fb7dc31c99","value":" 436k/436k [00:00&lt;00:00, 5.31MB/s]"}},"2ca4df7c9e4f4a0abe82ea90c2007e45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c1fcfdefea449cf928681797d6bab76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba554a1772da4784a80820e97f5d1a86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0fbb3f18d00441789aca756b0faa2ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b95c180aa7c3426d821a5a20abe2987b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4aecf4ee3a64f3d9bba525fe0e418c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9e128545e984d27876919fb7dc31c99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ce78dc059bc4885bc34367a7f01bcc6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d905ced34ffd45f782f03befc83af0ce","IPY_MODEL_e2932d78aeb14400ba5d682c2a14bbfd","IPY_MODEL_0aeec2d0fde443bda9356db9117625fb"],"layout":"IPY_MODEL_7bae06cd2849461e98e3234bcd1be61a"}},"d905ced34ffd45f782f03befc83af0ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_910856c6e7834ffeac8313d61580854d","placeholder":"​","style":"IPY_MODEL_cf5204c1c67046eebe38ed869dd4c90f","value":"tokenizer_config.json: 100%"}},"e2932d78aeb14400ba5d682c2a14bbfd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30959738dfba4d84ba592f708488f5fc","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c84f9a5aea2b4e3c8a84ec2a788877b1","value":48}},"0aeec2d0fde443bda9356db9117625fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c7ff2694374472f9227de7cda6a10f2","placeholder":"​","style":"IPY_MODEL_d7a42d56db9641f7b491c0265c017a64","value":" 48.0/48.0 [00:00&lt;00:00, 937B/s]"}},"7bae06cd2849461e98e3234bcd1be61a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"910856c6e7834ffeac8313d61580854d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf5204c1c67046eebe38ed869dd4c90f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30959738dfba4d84ba592f708488f5fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c84f9a5aea2b4e3c8a84ec2a788877b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c7ff2694374472f9227de7cda6a10f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7a42d56db9641f7b491c0265c017a64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9980751f97744829ebf0b1a463e19bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4dfaedd681bc4abaa940e0576e9e1e50","IPY_MODEL_ba775e1d26ba4cc7bd247e9dc34ba705","IPY_MODEL_5a31e1264f094805b6b7fff7913ed439"],"layout":"IPY_MODEL_26cbf5824114446485ab786fae55bd6d"}},"4dfaedd681bc4abaa940e0576e9e1e50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8a13c57945942b491a6ae189a003b0a","placeholder":"​","style":"IPY_MODEL_bfa5d77e6a034842b333a86029e9c816","value":"config.json: 100%"}},"ba775e1d26ba4cc7bd247e9dc34ba705":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b1b2b6a2ce04487a3930ddd44cee802","max":629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c469ae45dc834858a9eccbf0056b3c6a","value":629}},"5a31e1264f094805b6b7fff7913ed439":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2ea3d50884d4299893c1663443be74f","placeholder":"​","style":"IPY_MODEL_0f2c34f0f74644c491546a285d9c12ab","value":" 629/629 [00:00&lt;00:00, 14.7kB/s]"}},"26cbf5824114446485ab786fae55bd6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8a13c57945942b491a6ae189a003b0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfa5d77e6a034842b333a86029e9c816":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b1b2b6a2ce04487a3930ddd44cee802":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c469ae45dc834858a9eccbf0056b3c6a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2ea3d50884d4299893c1663443be74f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f2c34f0f74644c491546a285d9c12ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2aeae6088e24bd68611166efa81fc35":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b6ffe2a21934376809dcdf87d236832","IPY_MODEL_72e59af1c1fb48d5a8f980fcba770b59","IPY_MODEL_07ed2bbf79674d25a1368b33425184a2"],"layout":"IPY_MODEL_4dd8cff5112e426f9851891aec721ca3"}},"0b6ffe2a21934376809dcdf87d236832":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b205f2f870544746a5d8b967d6e6a95c","placeholder":"​","style":"IPY_MODEL_254ff6578f454941b38d93383a7debcf","value":"vocab.txt: 100%"}},"72e59af1c1fb48d5a8f980fcba770b59":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fadd274e2ae343088f9ca5679269d82e","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4edefcbb8b7849588468a59011907d40","value":231508}},"07ed2bbf79674d25a1368b33425184a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e641eb4489cb4b46928975c40b84759a","placeholder":"​","style":"IPY_MODEL_c9ec1c52a13a42a2bd18d15afad87749","value":" 232k/232k [00:00&lt;00:00, 2.10MB/s]"}},"4dd8cff5112e426f9851891aec721ca3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b205f2f870544746a5d8b967d6e6a95c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"254ff6578f454941b38d93383a7debcf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fadd274e2ae343088f9ca5679269d82e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4edefcbb8b7849588468a59011907d40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e641eb4489cb4b46928975c40b84759a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9ec1c52a13a42a2bd18d15afad87749":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"607654022f05466f826b4d6ccd23fe69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3dd5dfedd12412cace5eef5882ba1cb","IPY_MODEL_809beff14ea7411188cdf025db872fe5","IPY_MODEL_8ed2f41d611a4c32ba4563e7c6ccce1e"],"layout":"IPY_MODEL_5ce4c5f2571c498a985584cfa07e3680"}},"c3dd5dfedd12412cace5eef5882ba1cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c4270613853423cbfcc02b8b0a52c1e","placeholder":"​","style":"IPY_MODEL_939398e4730a42e589f129cdc1094cce","value":"model.safetensors: 100%"}},"809beff14ea7411188cdf025db872fe5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ada500cb39e4969a1f1cc08a1c3d599","max":267832558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ef9d4325f1347abb197805caf87f1a5","value":267832558}},"8ed2f41d611a4c32ba4563e7c6ccce1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f5086c9e26e4ed3b5b3ca1771bd663f","placeholder":"​","style":"IPY_MODEL_80a60e7275204ab4b101663aed556ded","value":" 268M/268M [00:03&lt;00:00, 56.9MB/s]"}},"5ce4c5f2571c498a985584cfa07e3680":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c4270613853423cbfcc02b8b0a52c1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"939398e4730a42e589f129cdc1094cce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ada500cb39e4969a1f1cc08a1c3d599":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ef9d4325f1347abb197805caf87f1a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f5086c9e26e4ed3b5b3ca1771bd663f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80a60e7275204ab4b101663aed556ded":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373,"referenced_widgets":["6e17e5818a5e41a6839c4ab78385e3b2","30c0d7d8c6e34e8d93902a445bc6f6c0","529c1557289d428e857db9a2a742290c","f87ce60860a440bd8537e616c822cf1f","60679a9b00c94ef6ab33f8503d226bf2","faba75b4d0f6471f8c8e340b002ea714","fd501224de07425ca0ea45ef7ffcd91e","d01f07dbc8af4b23b25d3e5a5aa108bb","626f2ce96f1641ccb78599a69ac835de","48edc9b4d7cf4f6f88ee9ca9ee066112","3a6d65434142402c858264b920a4156f","38071da472a8494aa38b0a0ba7ca638b","dc420ebe961140f5b7e6119760642780","9d72b9eebdd8484384aab0889dd7ec36","63812db4482b440eac5398412d6acbce","227fe9bb7b5e4d24bd42f0254221f88b","7bc9d20ce0454535b1043a36b19f7acc","1ea9b775420c4e2b9a05d0fbdd7a5d8b","27f8845b910b497e800e73ed054d429c","d6ad8439c6ac423fa000748bece43324","e4326c5c401c4898ba8cbfb6ec086ccd","f0dfd8355af447838ce193e180ad7340","344ac9cf24894f66b508eb5aef8c934a","76f9f04f5f9849679baf22c5b3542ddb","bd8fbaa1c9cf4321bfe6e6078bbe3274","05f8811e132b446a812bceea65f181c8","b5329605dcc1422ba874c8ab4133a46c","bb0f2aaaa6e44324b3869e74c2bdce8c","190c0928b2c84470ad48029f5994c811","54c4501ad471400ebdeb43f63e8fdc95","f47febc6af354bacac525feecc3fa53a","eaa5b134965446a79aae2a57554529d9","bc0a1a7d206a4ac5825a1509417e3ad3","9347ee2aa4914e8b9aaf006201c3d116","bd2ebbec8e8f44169dbd24a3d132edfd","f82c2108f6714baaa44cb7db85df095c","840f4aacdf0d4bac97d79c0477c1b600","3d8439e7a34d46deb9f0c75c907ddf93","b64fcedf99ba4103b7bd4fc4b1dbd488","8dbc33147e2d42efb8a331358f3c41d4","38ac59f231924f92acbd36b1fb627350","8665ef5b31ef423d9e0f1b1c196da94f","54b74a60a75e4398965f224b46c577a5","6cf502909e464282a198b0429e5df522"]},"id":"JKdIKopqLX7c","executionInfo":{"status":"ok","timestamp":1717872619583,"user_tz":-120,"elapsed":34807,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"5c0b6a3c-5353-4816-eeba-02ad6e40ea34"},"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e17e5818a5e41a6839c4ab78385e3b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38071da472a8494aa38b0a0ba7ca638b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"344ac9cf24894f66b508eb5aef8c934a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9347ee2aa4914e8b9aaf006201c3d116"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.9598048329353333},\n"," {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"]},"metadata":{},"execution_count":1}],"source":["from transformers import pipeline\n","\n","classifier = pipeline(\"sentiment-analysis\")\n","classifier(\n","    [\n","        \"I've been waiting for a HuggingFace course my whole life.\",\n","        \"I hate this so much!\",\n","    ]\n",")"]},{"cell_type":"markdown","source":["#**Preprocessing with a tokenizer[[preprocessing-with-a-tokenizer]]**#\n","##Like other neural networks, Transformer models can't process raw text directly, so the first step of our pipeline is to convert the text inputs into numbers that the model can make sense of. To do this we use a tokenizer, which will be responsible for:\n","\n","##*Splitting the input into words, subwords, or symbols (like punctuation) that are called tokens*\n","##*Mapping each token to an integer*\n","##*Adding additional inputs that may be useful to the model*\n","##All this preprocessing needs to be done in exactly the same way as when the model was pretrained, so we first need to download that information from the Model Hub. To do this, we use the AutoTokenizer class and its from_pretrained() method. Using the checkpoint name of our model, it will automatically fetch the data associated with the model's tokenizer and cache it (so it's only downloaded the first time you run the code below)."],"metadata":{"id":"DocIeDa7MOzk"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["93fdb76ec2394f22af2c466cade22fba","46ce3aa3bc4f4fb4b833ced41cf26443","56839213a95a493dbf227cb70cc5bcf4","b8806db47e414ab5b897b31f4b228ba7","60811ffa71ff46deb29b2d9ad02916c3","9a18b2b3fe1c43588614a25813226ebd","c6d4a6a693854dfa9df0946a734ae0b0","e6d3fb2d52d147e0a3cf83c18a039a74","253557115a78448db759d131c8f9c6d8","26f02d8c4fe848cdb9c8642b3acc7a4b","ae74c987a12d407b8bdec697d0b637a5","0cd414b4aabd4908a48098aa8f6dcb5a","5689ca4575cb40939ce333714cb6d4d9","48dc14cca17f4efeb73ffb2bb360f348","49ee1e0e20444729967756377f7bee9b","1ed65358abcc46fdb136258adf0e3f28","c0556fd93b37447fbe5b96c36ccfd469","05893daa12104670ab98f03ea7259f2c","80c5052ce18b45b3bb22e58882d9c347","5e4b1a9e5149432d96919a2cde7ebf0e","53955d5d23f143669573495054df5da7","fc9e71585695473fb56ee75e2bede6de","7d820e2194864c9cb567b789ccc8a522","6b7ab2303a7648e29268fff2142773ac","95be901b752f41f98c65996033373618","34e071be2cde4b9788b7d6e84dec5a86","452ed71aa6394d70b15492e76adca507","fe4eea21c22e4d7a93bf32c9cbbaf850","86ef1151372045fda16732d23407cc9e","30e0a561086247d09f797dee7bfd0d5c","d709f007f50544038b275a7a9c677e6d","a140dccd59c84c9eb79dfcd7ab183ff5","0398dfba7efd4a389a56440af5df9b30"]},"id":"FIJqDP_fMrv8","executionInfo":{"status":"ok","timestamp":1717872810931,"user_tz":-120,"elapsed":1264,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"2f6739d1-d55e-455f-81c6-d7c76de7b4f1"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93fdb76ec2394f22af2c466cade22fba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cd414b4aabd4908a48098aa8f6dcb5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d820e2194864c9cb567b789ccc8a522"}},"metadata":{}}]},{"cell_type":"markdown","source":["##Once we have the tokenizer, we can directly pass our sentences to it and we'll get back a dictionary that's ready to feed to our model! The only thing left to do is to convert the list of input IDs to tensors.\n","\n","##You can use 🤗 Transformers without having to worry about which ML framework is used as a backend; it might be PyTorch or TensorFlow, or Flax for some models. However, Transformer models only accept tensors as input. If this is your first time hearing about tensors, you can think of them as NumPy arrays instead. A NumPy array can be a scalar (0D), a vector (1D), a matrix (2D), or have more dimensions. It's effectively a tensor; other ML frameworks' tensors behave similarly, and are usually as simple to instantiate as NumPy arrays.\n","\n","##To specify the type of tensors we want to get back (PyTorch, TensorFlow, or plain NumPy), we use the return_tensors argument:"],"metadata":{"id":"riHBYAjaM9xq"}},{"cell_type":"code","source":["raw_inputs = [\n","        \"I've been waiting for a HuggingFace course my whole life.\",\n","            \"I hate this so much!\",\n","            ]\n","inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n","print(inputs)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"236tg67gNM6P","executionInfo":{"status":"ok","timestamp":1717872973403,"user_tz":-120,"elapsed":1403,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"fd5edfe1-9901-48da-e678-6e435fd5593c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n","          2607,  2026,  2878,  2166,  1012,   102],\n","        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n","             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"]}]},{"cell_type":"markdown","source":["#**Going through the model[[going-through-the-model]]**#\n","##We can download our pretrained model the same way we did with our tokenizer. 🤗 Transformers provides an AutoModel class which also has a from_pretrained() method:"],"metadata":{"id":"75CbGSWkNx-C"}},{"cell_type":"code","source":["from transformers import AutoModel\n","\n","checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","model = AutoModel.from_pretrained(checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["00378ba3f95f449ea528b1e526dc1741","438a92f95efa4be39e8bdc0e1aa1fc7d","b57df1200eae4e3483e57d377615b0fd","1b75b6d0757946018c19a4e19d70288b","4d4a4afd0820405992558636d7f55ee6","770126632f524a51ba3ce0a18596fe84","a535e84bedbe4fd3af24642dc8063299","ab1ec09fa5ff432ea76dc738c9f8e1bb","85573e7f5fa14062a0c930caa0eac95b","3f334b755a4f425c9729f0bfd8e0171f","fc6979bf718b4965bb3f8e0a40db6361"]},"id":"kCRhZOEeN9-K","executionInfo":{"status":"ok","timestamp":1717873150235,"user_tz":-120,"elapsed":3812,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"4635fc97-410b-4bbc-c6e7-69d32cc9db69"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00378ba3f95f449ea528b1e526dc1741"}},"metadata":{}}]},{"cell_type":"code","source":["from transformers import TFAutoModel\n","\n","checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","model = TFAutoModel.from_pretrained(checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IP80qaZHOKiB","executionInfo":{"status":"ok","timestamp":1717873207459,"user_tz":-120,"elapsed":3934,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"e4d21bf3-855a-4500-d281-9483004f4908"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n","- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]}]},{"cell_type":"markdown","source":["#**A high-dimensional vector?[[a-high-dimensional-vector]]**#\n","##The vector output by the Transformer module is usually large. It generally has three dimensions:\n","\n","##*Batch size: The number of sequences processed at a time (2 in our example).*\n","##*Sequence length: The length of the numerical representation of the sequence (16 in our example).*\n","##*Hidden size: The vector dimension of each model input.*\n","##It is said to be \"high dimensional\" because of the last value. The hidden size can be very large (768 is common for smaller models, and in larger models this can reach 3072 or more).\n","\n","We can see this if we feed the inputs we preprocessed to our model:"],"metadata":{"id":"CyL0hBOUO3Vr"}},{"cell_type":"code","source":["outputs = model(**inputs)\n","print(outputs.last_hidden_state.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":669},"id":"qZA9SAgbPK_A","executionInfo":{"status":"error","timestamp":1717873461099,"user_tz":-120,"elapsed":572,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"f61eca9c-a767-408b-a172-b531293e9977"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Exception encountered when calling layer 'tf_distil_bert_model' (type TFDistilBertModel).\n\nData of type <class 'torch.Tensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_distil_bert_model' (type TFDistilBertModel):\n  • input_ids=tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n          2607,  2026,  2878,  2166,  1012,   102],\n        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n  • attention_mask=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-150ac4a5641e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data of type {type(v)} is not allowed only {allowed_types} is accepted for {k}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_distil_bert_model' (type TFDistilBertModel).\n\nData of type <class 'torch.Tensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_distil_bert_model' (type TFDistilBertModel):\n  • input_ids=tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n          2607,  2026,  2878,  2166,  1012,   102],\n        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n             0,     0,     0,     0,     0,     0]])\n  • attention_mask=tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"]}]},{"source":["import tensorflow as tf\n","\n","# Assuming 'inputs' is a dictionary containing PyTorch tensors\n","inputs = {k: tf.convert_to_tensor(v.numpy()) for k, v in inputs.items()}\n","\n","outputs = model(**inputs)\n","print(outputs.last_hidden_state.shape)"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aIGEePANP3Cg","executionInfo":{"status":"ok","timestamp":1717873649161,"user_tz":-120,"elapsed":1217,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"3fab29ac-3741-439c-cc55-d9fa2feba9e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 16, 768)\n"]}]},{"cell_type":"markdown","source":["#**Model heads: Making sense out of numbers[[model-heads-making-sense-out-of-numbers]]**#"],"metadata":{"id":"6PzmCBbjQf5_"}},{"source":["import torch\n","from transformers import AutoModelForSequenceClassification\n","\n","checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","\n","# Assuming 'inputs' is a dictionary containing TensorFlow tensors\n","inputs = {k: torch.from_numpy(v.numpy()) for k, v in inputs.items()}\n","\n","outputs = model(**inputs)\n","# Access the logits instead of last_hidden_state\n","print(outputs.logits.shape)"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WhSf4fwjRHNJ","executionInfo":{"status":"ok","timestamp":1717873967719,"user_tz":-120,"elapsed":1198,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"5ac3e0fb-bdef-4ef2-e258-525da07f12dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 2])\n"]}]},{"source":["from transformers import TFAutoModelForSequenceClassification\n","import tensorflow as tf\n","\n","checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n","\n","# Ensure 'inputs' contains TensorFlow tensors\n","# Assuming original 'inputs' was a dictionary of PyTorch tensors\n","inputs = {k: tf.convert_to_tensor(v.numpy()) for k, v in inputs.items()}\n","\n","outputs = model(inputs) # Now the model should accept the inputs"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ofT0E_RhRn7G","executionInfo":{"status":"ok","timestamp":1717874111649,"user_tz":-120,"elapsed":4825,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"b8755302-12e5-4fa9-d32b-3804c9ab99f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n","\n","All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"]}]},{"cell_type":"code","source":["print(outputs.logits.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-88RwolRzfi","executionInfo":{"status":"ok","timestamp":1717874149376,"user_tz":-120,"elapsed":566,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"37fc7907-bf01-42fe-9cff-c5a19cd624f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 2)\n"]}]},{"cell_type":"code","source":["torch.Size([2, 2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vuyyYbuoR4El","executionInfo":{"status":"ok","timestamp":1717874171338,"user_tz":-120,"elapsed":537,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"b1ebafbb-464f-4962-8feb-eeb30a190715"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 2])"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["#**Postprocessing the output[[postprocessing-the-output]]**#\n","#The values we get as output from our model don't necessarily make sense by themselves. Let's take a look:"],"metadata":{"id":"ig9_1LD4SYau"}},{"cell_type":"code","source":["print(outputs.logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-u4cluMSgXw","executionInfo":{"status":"ok","timestamp":1717874333298,"user_tz":-120,"elapsed":10,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"3aa5b288-9195-47e2-e190-e153225b9420"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[-1.5606961  1.6122813]\n"," [ 4.1692314 -3.3464477]], shape=(2, 2), dtype=float32)\n"]}]},{"source":["import tensorflow as tf\n","\n","predictions = tf.nn.softmax(outputs.logits, axis=-1)\n","print(predictions)"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Gd-BktpTDen","executionInfo":{"status":"ok","timestamp":1717874490473,"user_tz":-120,"elapsed":586,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"64bf39d3-55e1-4233-bb6c-dfad54b2d55c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[4.0195391e-02 9.5980465e-01]\n"," [9.9945587e-01 5.4418371e-04]], shape=(2, 2), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["##Now we can see that the model predicted [0.0402, 0.9598] for the first sentence and [0.9995,  0.0005] for the second one. These are recognizable probability scores.\n","\n","##To get the labels corresponding to each position, we can inspect the id2label attribute of the model config (more on this in the next section):"],"metadata":{"id":"-trKTd5BT_Az"}},{"cell_type":"code","source":["model.config.id2label"],"metadata":{"id":"TTGBlOsWUHJ4","executionInfo":{"status":"ok","timestamp":1717874755079,"user_tz":-120,"elapsed":495,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"c005fdd4-eb59-46cb-bf3b-dc6113a198e3","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'NEGATIVE', 1: 'POSITIVE'}"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["#**Creating a Transformer[[creating-a-transformer]]**#\n","##The first thing we'll need to do to initialize a BERT model is load a configuration object:"],"metadata":{"id":"OSE_ZvZIIuZF"}},{"cell_type":"code","source":["from transformers import BertConfig, BertModel\n","\n","# Building the config\n","config = BertConfig()\n","\n","# Building the model from the config\n","model = BertModel(config)\n","\n","print(config)\n","\n","\n","#While you haven't seen what all of these attributes do yet,\n","#you should recognize some of them: the hidden_size attribute\n","#defines the size of the hidden_states vector, and num_hidden_layers\n","#defines the number of layers the Transformer model has."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"MwyauwyBJPCZ","executionInfo":{"status":"ok","timestamp":1717939213396,"user_tz":-120,"elapsed":4987,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"81b2f9ef-a103-422c-b55f-400e241c64f9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.41.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n"]}]},{"cell_type":"markdown","source":["#**Different loading methods[[different-loading-methods]]**#\n","##Creating a model from the default configuration initializes it with random values:"],"metadata":{"id":"IJnKIpKwKhIR"}},{"cell_type":"code","source":["from transformers import BertConfig, BertModel\n","\n","config = BertConfig()\n","model = BertModel(config)\n","\n","# Model is randomly initialized!"],"metadata":{"id":"hIQKrs8sKpS3","executionInfo":{"status":"ok","timestamp":1717939386407,"user_tz":-120,"elapsed":4225,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["##*Loading a Transformer model that is already trained is simple — we can do this using the from_pretrained() method:*##"],"metadata":{"id":"l3rwXlIGK5Rv"}},{"cell_type":"code","source":["from transformers import BertModel\n","\n","model = BertModel.from_pretrained(\"bert-base-cased\")\n","\n","#from transformers import TFBertModel\n","\n","#model = TFBertModel.from_pretrained(\"bert-base-cased\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205,"referenced_widgets":["eaf07a98715443aaa6a06c1cf7fc9ddf","07025233dc9b49b29faf20d1f29241aa","e8fa149f0561419f8ac6eebf41f90db9","e97d8b28734047bd818a3184f567b90d","e846c597c28f4abaa1b1a8ad8fe1fd3c","f5d33b29996241f6b4503a1ab001b991","2067c6e1bacd4e1e997b33dec04dde1d","67aadc5831d842b1af8fe7ed4b2ef877","5b490a1edd1c4c118bc5f1175d092196","3ce5f2c495c04a99bf47b0a3de7ac6c3","dbc3ca4d204843d8947b9f166a236808","6e0c7ed185374e63a7cf6822d7c32a8c","b238707e19d7405fa769ad4d39909115","e9d458a831bd4de68487578636d36e55","6578cb2736fa45ccbbc134f65c308b87","9776138890da42d2a7fc6a5852915d79","1a20414a36fd4bd5ba391e0507cccdfe","038ab46b57da48c38fda58f907ee44e1","54cc80267b6f4f6ea7fae8f4a6c1dd23","34d82571367740aa9bb73d9b88e36ae7","1c3beaa7960a42728dbb7f63e34bcd61","77b304953bf74d1780aa18573737a31d"]},"id":"8v1nVOrdLEcY","executionInfo":{"status":"ok","timestamp":1717939504940,"user_tz":-120,"elapsed":9746,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"62c1e02d-6661-4677-89eb-0f50796d9b2b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaf07a98715443aaa6a06c1cf7fc9ddf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e0c7ed185374e63a7cf6822d7c32a8c"}},"metadata":{}}]},{"cell_type":"markdown","source":["#**Saving methods[[saving-methods]]**#\n","##Saving a model is as easy as loading one — we use the save_pretrained() method, which is analogous to the from_pretrained() method:"],"metadata":{"id":"5dxaFT29L9Lg"}},{"cell_type":"code","source":["model.save_pretrained(\"directory_on_my_device\")"],"metadata":{"id":"xYW0HRwnMKRz","executionInfo":{"status":"ok","timestamp":1717939859591,"user_tz":-120,"elapsed":2971,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["#**Using a Transformer model for inference**#\n","##Now that you know how to load and save a model, let's try using it to make some predictions. Transformer models can only process numbers — numbers that the tokenizer generates. But before we discuss tokenizers, let's explore what inputs the model accepts.\n","\n","##Tokenizers can take care of casting the inputs to the appropriate framework's tensors, but to help you understand what's going on, we'll take a quick look at what must be done before sending the inputs to the model.\n","\n","##Let's say we have a couple of sequences:"],"metadata":{"id":"zXzJLjKjMsiU"}},{"cell_type":"code","source":["sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]"],"metadata":{"id":"sVchMcqrM6tD","executionInfo":{"status":"ok","timestamp":1717939978047,"user_tz":-120,"elapsed":445,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["##The tokenizer converts these to vocabulary indices which are typically called input IDs. Each sequence is now a list of numbers! The resulting output is:"],"metadata":{"id":"gdrhVg2END6Z"}},{"cell_type":"code","source":["encoded_sequences = [\n","        [101, 7592, 999, 102],\n","        [101, 4658, 1012, 102],\n","        [101, 3835, 999, 102],\n","                ]\n"],"metadata":{"id":"wvClEXsQNJjI","executionInfo":{"status":"ok","timestamp":1717940196671,"user_tz":-120,"elapsed":419,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["##This is a list of encoded sequences: a list of lists. Tensors only accept rectangular shapes (think matrices). This \"array\" is already of rectangular shape, so converting it to a tensor is easy:"],"metadata":{"id":"c4Z2LXPPNUi5"}},{"cell_type":"code","source":["import torch\n","\n","model_inputs = torch.tensor(encoded_sequences)\n"],"metadata":{"id":"6QfwmARDNcIG","executionInfo":{"status":"ok","timestamp":1717940203744,"user_tz":-120,"elapsed":10,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["#**Using the tensors as inputs to the model**#\n","##Making use of the tensors with the model is extremely simple — we just call the model with the inputs:"],"metadata":{"id":"BJSQ1ZQEN7kV"}},{"cell_type":"code","source":["output = model(model_inputs)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"0YwUpe47OGx4","executionInfo":{"status":"ok","timestamp":1717940361038,"user_tz":-120,"elapsed":489,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"f133ec0d-aa4b-4844-cecd-24bf3d8a5f7b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 4.4496e-01,  4.8276e-01,  2.7797e-01,  ..., -5.4032e-02,\n","           3.9393e-01, -9.4770e-02],\n","         [ 2.4943e-01, -4.4093e-01,  8.1772e-01,  ..., -3.1917e-01,\n","           2.2992e-01, -4.1172e-02],\n","         [ 1.3668e-01,  2.2518e-01,  1.4502e-01,  ..., -4.6915e-02,\n","           2.8224e-01,  7.5566e-02],\n","         [ 1.1789e+00,  1.6738e-01, -1.8187e-01,  ...,  2.4671e-01,\n","           1.0441e+00, -6.1972e-03]],\n","\n","        [[ 3.6436e-01,  3.2464e-02,  2.0258e-01,  ...,  6.0110e-02,\n","           3.2451e-01, -2.0996e-02],\n","         [ 7.1866e-01, -4.8725e-01,  5.1740e-01,  ..., -4.4012e-01,\n","           1.4553e-01, -3.7545e-02],\n","         [ 3.3223e-01, -2.3271e-01,  9.4876e-02,  ..., -2.5268e-01,\n","           3.2172e-01,  8.1085e-04],\n","         [ 1.2523e+00,  3.5754e-01, -5.1320e-02,  ..., -3.7840e-01,\n","           1.0526e+00, -5.6255e-01]],\n","\n","        [[ 2.4042e-01,  1.4718e-01,  1.2110e-01,  ...,  7.6062e-02,\n","           3.3564e-01,  2.8262e-01],\n","         [ 6.5701e-01, -3.2787e-01,  2.4968e-01,  ..., -2.5919e-01,\n","           2.0175e-01,  3.3275e-01],\n","         [ 2.0160e-01,  1.5783e-01,  9.8970e-03,  ..., -3.8850e-01,\n","           4.1307e-01,  3.9732e-01],\n","         [ 1.0175e+00,  6.4387e-01, -7.8147e-01,  ..., -4.2109e-01,\n","           1.0925e+00, -4.8456e-02]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.6856,  0.5262,  1.0000,  ...,  1.0000, -0.6112,  0.9971],\n","        [-0.6055,  0.4997,  0.9998,  ...,  0.9999, -0.6753,  0.9769],\n","        [-0.7702,  0.5447,  0.9999,  ...,  1.0000, -0.4655,  0.9894]],\n","       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"]}]},{"cell_type":"markdown","source":["#**Tokenizers**#\n","##Tokenizers are one of the core components of the NLP pipeline. They serve one purpose: to translate text into data that can be processed by the model. Models can only process numbers, so tokenizers need to convert our text inputs to numerical data. In this section, we'll explore exactly what happens in the tokenization pipeline.\n","\n","##In NLP tasks, the data that is generally processed is raw text. Here's an example of such text:\n","\n","##*Jim Henson was a puppeteer*\n","##However, models can only process numbers, so we need to find a way to convert the raw text to numbers. That's what the tokenizers do, and there are a lot of ways to go about this. The goal is to find the most meaningful representation — that is, the one that makes the most sense to the model — and, if possible, the smallest representation.\n","\n","##Let's take a look at some examples of tokenization algorithms, and try to answer some of the questions you may have about tokenization.\n","\n","##**Word-based**##\n","##The first type of tokenizer that comes to mind is word-based. It's generally very easy to set up and use with only a few rules, and it often yields decent results. For example, in the image below, the goal is to split the raw text into words and find a numerical representation for each of them:"],"metadata":{"id":"hVZgMKd7PyZq"}},{"cell_type":"markdown","source":["#*There are different ways to split the text. For example, we could use whitespace to tokenize the text into words by applying Python's split() function:*#"],"metadata":{"id":"geCO_-bzQa7v"}},{"cell_type":"code","source":["tokenized_text = \"Jim Henson was a puppeteer\".split()\n","print(tokenized_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CVhTMpSQQirK","executionInfo":{"status":"ok","timestamp":1717940929773,"user_tz":-120,"elapsed":535,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"2e88150f-172d-4a88-cf88-4768eacfb4cf"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["['Jim', 'Henson', 'was', 'a', 'puppeteer']\n"]}]},{"cell_type":"markdown","source":["#**Character-based**#\n","##Character-based tokenizers split the text into characters, rather than words. This has two primary benefits:\n","\n","##*The vocabulary is much smaller.*\n","##*There are much fewer out-of-vocabulary (unknown) tokens, since every word can be built from characters.*\n","##But here too some questions arise concerning spaces and punctuation:\n","\n","\n","##This approach isn't perfect either. Since the representation is now based on characters rather than words, one could argue that, intuitively, it's less meaningful: each character doesn't mean a lot on its own, whereas that is the case with words. However, this again differs according to the language; in Chinese, for example, each character carries more information than a character in a Latin language.\n","\n","##Another thing to consider is that we'll end up with a very large amount of tokens to be processed by our model: whereas a word would only be a single token with a word-based tokenizer, it can easily turn into 10 or more tokens when converted into characters.\n","\n","##To get the best of both worlds, we can use a third technique that combines the two approaches: subword tokenization.\n","\n","#*Subword tokenization*#"],"metadata":{"id":"hDDzJzPORJ_e"}},{"cell_type":"markdown","source":["#**Subword tokenization**#\n","##Subword tokenization algorithms rely on the principle that frequently used words should not be split into smaller subwords, but rare words should be decomposed into meaningful subwords.\n","\n","##For instance, \"annoyingly\" might be considered a rare word and could be decomposed into \"annoying\" and \"ly\". These are both likely to appear more frequently as standalone subwords, while at the same time the meaning of \"annoyingly\" is kept by the composite meaning of \"annoying\" and \"ly\".\n","\n","\n","##These subwords end up providing a lot of semantic meaning: for instance, in the example above \"tokenization\" was split into \"token\" and \"ization\", two tokens that have a semantic meaning while being space-efficient (only two tokens are needed to represent a long word). This allows us to have relatively good coverage with small vocabularies, and close to no unknown tokens.\n","\n","##This approach is especially useful in agglutinative languages such as Turkish, where you can form (almost) arbitrarily long complex words by stringing together subwords."],"metadata":{"id":"_V60mxx9SQjd"}},{"cell_type":"markdown","source":["##**And more!**##\n","##Unsurprisingly, there are many more techniques out there. To name a few:\n","\n","##*Byte-level BPE, as used in GPT-2*\n","##*WordPiece, as used in BERT*\n","##*SentencePiece or Unigram, as used in several multilingual models*\n","##You should now have sufficient knowledge of how tokenizers work to get started with the API."],"metadata":{"id":"a3e-27eaS6uV"}},{"cell_type":"markdown","source":["#**Loading and saving**#\n","##Loading and saving tokenizers is as simple as it is with models. Actually, it's based on the same two methods: from_pretrained() and save_pretrained(). These methods will load or save the algorithm used by the tokenizer (a bit like the architecture of the model) as well as its vocabulary (a bit like the weights of the model).\n","\n","##Loading the BERT tokenizer trained with the same checkpoint as BERT is done the same way as loading the model, except we use the BertTokenizer class:"],"metadata":{"id":"OHEHoSRxTWNw"}},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["95948ee246774ca980060910686b1028","4a7c64decf4c49419ccd17ec9f739ea5","8d517c9ef4b3472eba2c3c55b50cc455","5ba04d1c243d4e34a32ad0fcf0fdb3e7","ae78cc09b5514047aed585f94dd5f6b1","2947503a6dc8496bbc1133bb5ce9df41","9d56542abdb840f9a30bb09437576bae","f96a5180825f4c70b2e7e028b052bb5d","08383b886ca04b6fa38eca0dca69282b","3b878cce7ead4e728e1f7dca88f287b5","a27a806b9b3c4c209d3e7963ea96eb3a","d828d16be34e42cab1b085dbabfba3c4","ba67d2db9a054d99bd66aebad0ed3705","00d579fe48c74f8f964a5e59201f1bd9","a0be4afc2b5c4d1faad20ae8b1e0f6e8","5ad67aa415e3423aa05280359d289650","4a2e49fa62184b3d84acc2e6f236c35b","ab1b101b6c944b239ade4e182a6c9519","fbef4ed937af4af1991d1501fa90f11d","ac153a59e71e44ffbc3763c08e62a34c","58983126efdd4079a6e8913d8e9e614a","fe4d789a24454d709c390282e46c656f","6f8756c7f8b24f918a651b9ce5aa0d72","4e38fbb79eb345e8aa8175fbd527c327","98b4c1814ff145818b6df8ca334a0e4b","3ff342c5f2cb4cd1a9f6e9815a3d69af","2ca4df7c9e4f4a0abe82ea90c2007e45","2c1fcfdefea449cf928681797d6bab76","ba554a1772da4784a80820e97f5d1a86","a0fbb3f18d00441789aca756b0faa2ee","b95c180aa7c3426d821a5a20abe2987b","c4aecf4ee3a64f3d9bba525fe0e418c5","d9e128545e984d27876919fb7dc31c99"]},"id":"bgKrfeTYTsRU","executionInfo":{"status":"ok","timestamp":1717941759373,"user_tz":-120,"elapsed":5706,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"35467cf2-a081-498e-80c7-13a73225689a"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95948ee246774ca980060910686b1028"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d828d16be34e42cab1b085dbabfba3c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f8756c7f8b24f918a651b9ce5aa0d72"}},"metadata":{}}]},{"cell_type":"markdown","source":["##Similar to AutoModel, the AutoTokenizer class will grab the proper tokenizer class in the library based on the checkpoint name, and can be used directly with any checkpoint:"],"metadata":{"id":"XteohQmFUGSb"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"],"metadata":{"id":"JVt0_Xu5UUVl","executionInfo":{"status":"ok","timestamp":1717941920591,"user_tz":-120,"elapsed":504,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["##**We can now use the tokenizer as shown in the previous section:*##"],"metadata":{"id":"91FcRzsLUcpz"}},{"cell_type":"code","source":["tokenizer(\"Using a Transformer network is simple\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMAgzej2UnqE","executionInfo":{"status":"ok","timestamp":1717942011029,"user_tz":-120,"elapsed":33,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"867c1dff-aa73-4b96-8ab3-288ed3d8fb70"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [101, 7993, 170, 13809, 23763, 2443, 1110, 3014, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["#**Saving a tokenizer is identical to saving a model:*##"],"metadata":{"id":"hypIFbRkU-CC"}},{"cell_type":"code","source":["tokenizer.save_pretrained(\"directory_on_my_computer\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kGf2wx1ZVE-f","executionInfo":{"status":"ok","timestamp":1717942131062,"user_tz":-120,"elapsed":11,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"87567dda-a3f6-4384-a2d4-7fd9bf7293ff"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('directory_on_my_computer/tokenizer_config.json',\n"," 'directory_on_my_computer/special_tokens_map.json',\n"," 'directory_on_my_computer/vocab.txt',\n"," 'directory_on_my_computer/added_tokens.json',\n"," 'directory_on_my_computer/tokenizer.json')"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["#**Encoding**#\n","##Translating text to numbers is known as encoding. Encoding is done in a two-step process: the tokenization, followed by the conversion to input IDs.\n","\n","##As we've seen, the first step is to split the text into words (or parts of words, punctuation symbols, etc.), usually called tokens. There are multiple rules that can govern that process, which is why we need to instantiate the tokenizer using the name of the model, to make sure we use the same rules that were used when the model was pretrained.\n","\n","##The second step is to convert those tokens into numbers, so we can build a tensor out of them and feed them to the model. To do this, the tokenizer has a vocabulary, which is the part we download when we instantiate it with the from_pretrained() method. Again, we need to use the same vocabulary used when the model was pretrained.\n","\n","##To get a better understanding of the two steps, we'll explore them separately. Note that we will use some methods that perform parts of the tokenization pipeline separately to show you the intermediate results of those steps, but in practice, you should call the tokenizer directly on your inputs (as shown in the section 2).\n","\n","##**Tokenization**##\n","##The tokenization process is done by the tokenize() method of the tokenizer:"],"metadata":{"id":"SiSGI16wX20f"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n","\n","sequence = \"Using a Transformer network is simple\"\n","tokens = tokenizer.tokenize(sequence)\n","\n","print(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LtUdGIFYTyV","executionInfo":{"status":"ok","timestamp":1717943060353,"user_tz":-120,"elapsed":501,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"4e28709e-0b4c-49db-d32f-02c2db7f0618"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n"]}]},{"cell_type":"markdown","source":["##**From tokens to input IDs**##\n","##*The conversion to input IDs is handled by the convert_tokens_to_ids() tokenizer method:*##"],"metadata":{"id":"A0qSn-gZY4Gt"}},{"cell_type":"code","source":["ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","print(ids)\n","#These outputs, once converted to the appropriate framework tensor,\n","#can then be used as inputs to a model as seen earlier in this chapter."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GmF_QQSLZHj9","executionInfo":{"status":"ok","timestamp":1717943179153,"user_tz":-120,"elapsed":626,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"e9761e7c-1c98-4b30-a884-70e17468c886"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[7993, 170, 13809, 23763, 2443, 1110, 3014]\n"]}]},{"cell_type":"markdown","source":["##**Decoding**##\n","###*Decoding is going the other way around: from vocabulary indices, we want to get a string. This can be done with the decode() method as follows:*##"],"metadata":{"id":"R9lmgOx_ZldI"}},{"cell_type":"code","source":["decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\n","print(decoded_string)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ll-Qg9oqZ0cc","executionInfo":{"status":"ok","timestamp":1717943380905,"user_tz":-120,"elapsed":10874,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"261f879d-195a-4a68-f7cd-36ebdf558325"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Using a transformer network is simple\n"]}]},{"cell_type":"markdown","source":["##Note that the decode method not only converts the indices back to tokens, but also groups together the tokens that were part of the same words to produce a readable sentence. This behavior will be extremely useful when we use models that predict new text (either text generated from a prompt, or for sequence-to-sequence problems like translation or summarization).\n","\n","##By now you should understand the atomic operations a tokenizer can handle: tokenization, conversion to IDs, and converting IDs back to a string. However, we've just scraped the tip of the iceberg. In the following section, we'll take our approach to its limits and take a look at how to overcome them."],"metadata":{"id":"UzLIEdS3aMwU"}},{"cell_type":"markdown","source":["#**Models expect a batch of inputs**#\n","##In the previous exercise you saw how sequences get translated into lists of numbers. Let's convert this list of numbers to a tensor and send it to the model:"],"metadata":{"id":"ks19phsZapEi"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","\n","sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n","\n","tokens = tokenizer.tokenize(sequence)\n","ids = tokenizer.convert_tokens_to_ids(tokens)\n","input_ids = torch.tensor(ids)\n","# This line will fail.\n","model(input_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":539,"referenced_widgets":["9ce78dc059bc4885bc34367a7f01bcc6","d905ced34ffd45f782f03befc83af0ce","e2932d78aeb14400ba5d682c2a14bbfd","0aeec2d0fde443bda9356db9117625fb","7bae06cd2849461e98e3234bcd1be61a","910856c6e7834ffeac8313d61580854d","cf5204c1c67046eebe38ed869dd4c90f","30959738dfba4d84ba592f708488f5fc","c84f9a5aea2b4e3c8a84ec2a788877b1","9c7ff2694374472f9227de7cda6a10f2","d7a42d56db9641f7b491c0265c017a64","b9980751f97744829ebf0b1a463e19bb","4dfaedd681bc4abaa940e0576e9e1e50","ba775e1d26ba4cc7bd247e9dc34ba705","5a31e1264f094805b6b7fff7913ed439","26cbf5824114446485ab786fae55bd6d","f8a13c57945942b491a6ae189a003b0a","bfa5d77e6a034842b333a86029e9c816","3b1b2b6a2ce04487a3930ddd44cee802","c469ae45dc834858a9eccbf0056b3c6a","d2ea3d50884d4299893c1663443be74f","0f2c34f0f74644c491546a285d9c12ab","e2aeae6088e24bd68611166efa81fc35","0b6ffe2a21934376809dcdf87d236832","72e59af1c1fb48d5a8f980fcba770b59","07ed2bbf79674d25a1368b33425184a2","4dd8cff5112e426f9851891aec721ca3","b205f2f870544746a5d8b967d6e6a95c","254ff6578f454941b38d93383a7debcf","fadd274e2ae343088f9ca5679269d82e","4edefcbb8b7849588468a59011907d40","e641eb4489cb4b46928975c40b84759a","c9ec1c52a13a42a2bd18d15afad87749","607654022f05466f826b4d6ccd23fe69","c3dd5dfedd12412cace5eef5882ba1cb","809beff14ea7411188cdf025db872fe5","8ed2f41d611a4c32ba4563e7c6ccce1e","5ce4c5f2571c498a985584cfa07e3680","1c4270613853423cbfcc02b8b0a52c1e","939398e4730a42e589f129cdc1094cce","1ada500cb39e4969a1f1cc08a1c3d599","8ef9d4325f1347abb197805caf87f1a5","6f5086c9e26e4ed3b5b3ca1771bd663f","80a60e7275204ab4b101663aed556ded"]},"collapsed":true,"id":"0oInx6w3bTEd","executionInfo":{"status":"error","timestamp":1717943756999,"user_tz":-120,"elapsed":7901,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"6511f9d5-8842-490e-b923-fad3b2e28eaa"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ce78dc059bc4885bc34367a7f01bcc6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9980751f97744829ebf0b1a463e19bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2aeae6088e24bd68611166efa81fc35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"607654022f05466f826b4d6ccd23fe69"}},"metadata":{}},{"output_type":"error","ename":"IndexError","evalue":"too many indices for tensor of dimension 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-2b9fc1b6cd40>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# This line will fail.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[1;32m    992\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_padding_and_no_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mwarn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   4455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4456\u001b[0m         \u001b[0;31m# Check only the first and last input IDs to reduce overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4457\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4458\u001b[0m             warn_string = (\n\u001b[1;32m   4459\u001b[0m                 \u001b[0;34m\"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"]}]},{"cell_type":"markdown","source":["##The problem is that we sent a single sequence to the model, whereas 🤗 Transformers models expect multiple sentences by default. Here we tried to do everything the tokenizer did behind the scenes when we applied it to a sequence. But if you look closely, you'll see that the tokenizer didn't just convert the list of input IDs into a tensor, it added a dimension on top of it:"],"metadata":{"id":"6rNFYl2Jbs3P"}},{"cell_type":"code","source":["tokenized_inputs = tokenizer(sequence, return_tensors=\"pt\")\n","print(tokenized_inputs[\"input_ids\"])\n","\n","#tokenized_inputs = tokenizer(sequence, return_tensors=\"tf\")\n","#print(tokenized_inputs[\"input_ids\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"54M7OkRobzYW","executionInfo":{"status":"ok","timestamp":1717943942662,"user_tz":-120,"elapsed":481,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"529afb83-cac9-415a-bf34-fdfca9748cf9"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n","          2607,  2026,  2878,  2166,  1012,   102]])\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","\n","sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n","\n","tokens = tokenizer.tokenize(sequence)\n","ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","input_ids = torch.tensor([ids])\n","print(\"Input IDs:\", input_ids)\n","\n","output = model(input_ids)\n","print(\"Logits:\", output.logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"imB7WYTMcSXl","executionInfo":{"status":"ok","timestamp":1717944013117,"user_tz":-120,"elapsed":1471,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"85a18337-f406-4384-ab18-0fbb41f81a98"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Input IDs: tensor([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n","          2026,  2878,  2166,  1012]])\n","Logits: tensor([[-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"markdown","source":["##Batching is the act of sending multiple sentences through the model, all at once. If you only have one sentence, you can just build a batch with a single sequence:\n","\n","##batched_ids = [ids, ids]\n","##This is a batch of two identical sequences!\n","\n","##Batching allows the model to work when you feed it multiple sentences. Using multiple sequences is just as simple as building a batch with a single sequence. There's a second issue, though. When you're trying to batch together two (or more) sentences, they might be of different lengths. If you've ever worked with tensors before, you know that they need to be of rectangular shape, so you won't be able to convert the list of input IDs into a tensor directly. To work around this problem, we usually pad the inputs."],"metadata":{"id":"pck8_hfVc21K"}},{"cell_type":"markdown","source":["#**Padding the inputs**#\n","##The following list of lists cannot be converted to a tensor:"],"metadata":{"id":"gSkchTendNx4"}},{"cell_type":"code","source":["batched_ids = [\n","        [200, 200, 200],\n","        [200, 200]\n","            ]\n"],"metadata":{"id":"OsRzX0GvdYOA","executionInfo":{"status":"ok","timestamp":1717944300345,"user_tz":-120,"elapsed":670,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["##In order to work around this, we'll use padding to make our tensors have a rectangular shape. Padding makes sure all our sentences have the same length by adding a special word called the padding token to the sentences with fewer values. For example, if you have 10 sentences with 10 words and 1 sentence with 20 words, padding will ensure all the sentences have 20 words. In our example, the resulting tensor looks like this:"],"metadata":{"id":"Rgq59nW_dkuL"}},{"cell_type":"code","source":["padding_id = 100\n","\n","batched_ids = [\n","    [200, 200, 200],\n","    [200, 200, padding_id],\n","        ]\n","\n","print(batched_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JIRvj-AydriW","executionInfo":{"status":"ok","timestamp":1717944413941,"user_tz":-120,"elapsed":672,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"18afaff1-c899-4d4d-df5b-faac5918cb47"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["[[200, 200, 200], [200, 200, 100]]\n"]}]},{"cell_type":"markdown","source":["##The padding token ID can be found in tokenizer.pad_token_id. Let's use it and send our two sentences through the model individually and batched together:"],"metadata":{"id":"bwSI4_pzeRlb"}},{"cell_type":"code","source":["model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","\n","sequence1_ids = [[200, 200, 200]]\n","sequence2_ids = [[200, 200]]\n","batched_ids = [\n","    [200, 200, 200],\n","        [200, 200, tokenizer.pad_token_id],\n","        ]\n","\n","print(model(torch.tensor(sequence1_ids)).logits)\n","print(model(torch.tensor(sequence2_ids)).logits)\n","print(model(torch.tensor(batched_ids)).logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lFgcPK5menSf","executionInfo":{"status":"ok","timestamp":1717944640307,"user_tz":-120,"elapsed":1156,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"de4f92eb-7adf-4584-c00e-cbb6176f3bb6"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"]},{"output_type":"stream","name":"stdout","text":["tensor([[ 1.5694, -1.3895]], grad_fn=<AddmmBackward0>)\n","tensor([[ 0.5803, -0.4125]], grad_fn=<AddmmBackward0>)\n","tensor([[ 1.5694, -1.3895],\n","        [ 1.3374, -1.2163]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"markdown","source":["#**Attention masks**#\n","##Attention masks are tensors with the exact same shape as the input IDs tensor, filled with 0s and 1s: 1s indicate the corresponding tokens should be attended to, and 0s indicate the corresponding tokens should not be attended to (i.e., they should be ignored by the attention layers of the model).\n","\n","##Let's complete the previous example with an attention mask:"],"metadata":{"id":"v-V24u5xfOYD"}},{"cell_type":"code","source":["batched_ids = [\n","        [200, 200, 200],\n","            [200, 200, tokenizer.pad_token_id],\n","            ]\n","\n","attention_mask = [\n","            [1, 1, 1],\n","            [1, 1, 0],\n","                    ]\n","\n","outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))\n","print(outputs.logits)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0w4uJodxflHa","executionInfo":{"status":"ok","timestamp":1717944918466,"user_tz":-120,"elapsed":462,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"4fafa2c5-abaa-480a-d813-d30ca861320f"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.5694, -1.3895],\n","        [ 0.5803, -0.4125]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"markdown","source":["#**Putting it all together**#\n","##In the last few sections, we've been trying our best to do most of the work by hand. We've explored how tokenizers work and looked at tokenization, conversion to input IDs, padding, truncation, and attention masks.\n","\n","##However, as we saw in section 2, the 🤗 Transformers API can handle all of this for us with a high-level function that we'll dive into here. When you call your tokenizer directly on the sentence, you get back inputs that are ready to pass through your model:"],"metadata":{"id":"fEquXlc4gCKO"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","\n","sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n","\n","model_inputs = tokenizer(sequence)"],"metadata":{"id":"3R6Ftec2gcKh","executionInfo":{"status":"ok","timestamp":1717945096986,"user_tz":-120,"elapsed":509,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["#*Here, the model_inputs variable contains everything that's necessary for a model to operate well. For DistilBERT, that includes the input IDs as well as the attention mask. Other models that accept additional inputs will also have those output by the tokenizer object.*#"],"metadata":{"id":"hsCPqLGfgj_x"}},{"cell_type":"code","source":["sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n","\n","model_inputs = tokenizer(sequence)"],"metadata":{"id":"wyog4yegg9r-","executionInfo":{"status":"ok","timestamp":1717945236741,"user_tz":-120,"elapsed":678,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["#*It also handles multiple sequences at a time, with no change in the API:*#"],"metadata":{"id":"NuT3TeW2hDFH"}},{"cell_type":"code","source":["sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n","\n","model_inputs = tokenizer(sequences)"],"metadata":{"id":"ao4r6jZwhJD4","executionInfo":{"status":"ok","timestamp":1717945279364,"user_tz":-120,"elapsed":485,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["#*It can pad according to several objectives:*#"],"metadata":{"id":"QzvxZtSEhRD0"}},{"cell_type":"code","source":["# Will pad the sequences up to the maximum sequence length\n","model_inputs1 = tokenizer(sequences, padding=\"longest\")\n","print(model_inputs1)\n","\n","# Will pad the sequences up to the model max length\n","# (512 for BERT or DistilBERT)\n","model_inputs2 = tokenizer(sequences, padding=\"max_length\")\n","print (model_inputs2)\n","\n","# Will pad the sequences up to the specified max length\n","model_inputs3 = tokenizer(sequences, padding=\"max_length\", max_length=8)\n","print(model_inputs3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UUwpzPGXhcOK","executionInfo":{"status":"ok","timestamp":1717945528507,"user_tz":-120,"elapsed":434,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"85fde69c-838d-483d-8d18-1070773ca37c"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [[101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102], [101, 2061, 2031, 1045, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n","{'input_ids': [[101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2061, 2031, 1045, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n","{'input_ids': [[101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102], [101, 2061, 2031, 1045, 999, 102, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0]]}\n"]}]},{"cell_type":"code","source":["sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n","\n","# Will truncate the sequences that are longer than the model max length\n","# (512 for BERT or DistilBERT)\n","model_inputs = tokenizer(sequences, truncation=True)\n","\n","# Will truncate the sequences that are longer than the specified max length\n","model_inputs = tokenizer(sequences, max_length=8, truncation=True)"],"metadata":{"id":"mX629QhmiVdg","executionInfo":{"status":"ok","timestamp":1717945598652,"user_tz":-120,"elapsed":618,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["##The tokenizer object can handle the conversion to specific framework tensors, which can then be directly sent to the model. For example, in the following code sample we are prompting the tokenizer to return tensors from the different frameworks — \"pt\" returns PyTorch tensors, \"tf\" returns TensorFlow tensors, and \"np\" returns NumPy arrays:"],"metadata":{"id":"z3D4kXlkindi"}},{"cell_type":"code","source":["sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n","\n","# Returns PyTorch tensors\n","model_inputs1 = tokenizer(sequences, padding=True, return_tensors=\"pt\")\n","print(model_inputs1)\n","\n","\n","# Returns TensorFlow tensors\n","model_inputs2 = tokenizer(sequences, padding=True, return_tensors=\"tf\")\n","print(model_inputs2)\n","\n","# Returns NumPy arrays\n","model_inputs3 = tokenizer(sequences, padding=True, return_tensors=\"np\")\n","print(model_inputs3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"45IAcPahiuMB","executionInfo":{"status":"ok","timestamp":1717945838013,"user_tz":-120,"elapsed":466,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"192f62ce-4100-4080-e05b-d8c1a7d18622"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n","          2607,  2026,  2878,  2166,  1012,   102],\n","        [  101,  2061,  2031,  1045,   999,   102,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n","{'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n","array([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662,\n","        12172,  2607,  2026,  2878,  2166,  1012,   102],\n","       [  101,  2061,  2031,  1045,   999,   102,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n","array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}\n","{'input_ids': array([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662,\n","        12172,  2607,  2026,  2878,  2166,  1012,   102],\n","       [  101,  2061,  2031,  1045,   999,   102,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"]}]},{"cell_type":"markdown","source":["#**Special tokens**#\n","##If we take a look at the input IDs returned by the tokenizer, we will see they are a tiny bit different from what we had earlier:"],"metadata":{"id":"gNe9krsvjbj1"}},{"cell_type":"code","source":["sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n","\n","model_inputs = tokenizer(sequence)\n","print(model_inputs[\"input_ids\"])\n","\n","tokens = tokenizer.tokenize(sequence)\n","ids = tokenizer.convert_tokens_to_ids(tokens)\n","print(ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHosUKktjrT_","executionInfo":{"status":"ok","timestamp":1717945946125,"user_tz":-120,"elapsed":452,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"7c013206-940f-46a5-ecc8-e5257c39ebac"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["[101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102]\n","[1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012]\n"]}]},{"cell_type":"markdown","source":["##One token ID was added at the beginning, and one at the end. Let's decode the two sequences of IDs above to see what this is about:"],"metadata":{"id":"uDQgsUobj61v"}},{"cell_type":"code","source":["print(tokenizer.decode(model_inputs[\"input_ids\"]))\n","print(tokenizer.decode(ids))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4YreGbDkEAi","executionInfo":{"status":"ok","timestamp":1717946046290,"user_tz":-120,"elapsed":497,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"2e1afac2-a2a3-4309-bd9f-fc3f5a6b34c8"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] i've been waiting for a huggingface course my whole life. [SEP]\n","i've been waiting for a huggingface course my whole life.\n"]}]},{"cell_type":"markdown","source":["###The tokenizer added the special word [CLS] at the beginning and the special word [SEP] at the end. This is because the model was pretrained with those, so to get the same results for inference we need to add them as well. Note that some models don't add special words, or add different ones; models may also add these special words only at the beginning, or only at the end. In any case, the tokenizer knows which ones are expected and will deal with this for you."],"metadata":{"id":"dz0YGr1PlApN"}},{"cell_type":"markdown","source":["Wrapping up: From tokenizer to model[[wrapping-up-from-tokenizer-to-model]]\n","Now that we've seen all the individual steps the tokenizer object uses when applied on texts, let's see one final time how it can handle multiple sequences (padding!), very long sequences (truncation!), and multiple types of tensors with its main API:"],"metadata":{"id":"6MXn2A-ZlMzG"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n","\n","tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n","output = model(**tokens)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RNWkwmBwmCsQ","executionInfo":{"status":"ok","timestamp":1717946604262,"user_tz":-120,"elapsed":2014,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"3be233ab-80fe-418b-e8de-e44aceb5141b"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n","        [-3.6183,  3.9137]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"]}]}]}